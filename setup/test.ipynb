{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('aml': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a5d4df4a22655ddcd3995113ae21abdf5e3f153b58eb8770b042525e3ea05670"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tenant ID: 72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "Subscription ID: 3e0e14b3-7e28-4da7-97de-0f5cb324f030\n",
      "Resource Group:  ml\n",
      "Workspace Name: ml-service\n",
      "Library configuration succeeded\n"
     ]
    }
   ],
   "source": [
    "%run ./setup-aml.ipynb\n",
    "aml_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.core import PipelineParameter\n",
    "from azureml.pipeline.steps import EstimatorStep\n",
    "from azureml.train.dnn import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    num_epochs = PipelineParameter(name='num_epochs', default_value=25)\n",
    "    batch_size = PipelineParameter(name='batch_size', default_value=16)\n",
    "    learning_rate = PipelineParameter(name='learning_rate', default_value=0.001)\n",
    "    momentum = PipelineParameter(name='momentum', default_value=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.core import PipelineParameter\n",
    "from azureml.pipeline.steps import EstimatorStep\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.pipeline.steps import CommandStep\n",
    "\n",
    "def train_step(train_dir, valid_dir, compute_target, work_space):\n",
    "    '''\n",
    "    This step will fine-tune a RESNET-18 model on our dataset using PyTorch. \n",
    "    It will use the corresponding input image directories as training and validation data.\n",
    "\n",
    "    :param train_dir: The reference to the directory containing the training data\n",
    "    :type train_dir: DataReference\n",
    "    :param valid_dir: The reference to the directory containing the validation data\n",
    "    :type valid_dir: DataReference\n",
    "    :param compute_target: The compute target to run the step on\n",
    "    :type compute_target: ComputeTarget\n",
    "    \n",
    "    :return: The preprocess step, step outputs dictionary (keys: model_dir)\n",
    "    :rtype: EstimatorStep, dict\n",
    "    '''\n",
    "\n",
    "    num_epochs = PipelineParameter(name='num_epochs', default_value=25)\n",
    "    batch_size = PipelineParameter(name='batch_size', default_value=16)\n",
    "    learning_rate = PipelineParameter(name='learning_rate', default_value=0.001)\n",
    "    momentum = PipelineParameter(name='momentum', default_value=0.9)\n",
    "\n",
    "    model_dir = PipelineData(\n",
    "        name='model_dir', \n",
    "        pipeline_output_name='model_dir',\n",
    "        datastore=train_dir.datastore,\n",
    "        output_mode='mount',\n",
    "        is_directory=True)\n",
    "\n",
    "    outputs = [model_dir]\n",
    "    outputs_map = { 'model_dir': model_dir }\n",
    "\n",
    "\n",
    "    curated_env_name = 'AzureML-PyTorch-1.6-GPU'\n",
    "    pytorch_env = Environment.get(workspace=work_space, name=curated_env_name)\n",
    "    step = EstimatorStep(\n",
    "        estimator=estimator,\n",
    "        estimator_entry_script_arguments=[\n",
    "            '--train_dir', train_dir, \n",
    "            '--valid_dir', valid_dir, \n",
    "            '--output_dir', model_dir, \n",
    "            '--num_epochs', num_epochs, \n",
    "            '--batch_size', batch_size,\n",
    "            '--learning_rate', learning_rate, \n",
    "            '--momentum', momentum\n",
    "        ],\n",
    "        inputs=[train_dir, valid_dir],\n",
    "        compute_target=compute_target,\n",
    "        outputs=outputs,\n",
    "        allow_reuse=False)\n",
    "    train_config = ScriptRunConfig(source_directory=os.path.dirname(os.path.abspath(__file__)),\n",
    "                      script='pytorch_train.py',\n",
    "                      arguments=['--num_epochs', 30, '--output_dir', './outputs',  '--train_dir', train_dir, \n",
    "                                      '--valid_dir', valid_dir, \n",
    "                                      '--output_dir', model_dir, \n",
    "                                      '--num_epochs', num_epochs, \n",
    "                                      '--batch_size', batch_size,\n",
    "                                      '--learning_rate', learning_rate, \n",
    "                                      '--momentum', momentum\n",
    "                                    ],\n",
    "                      compute_target=compute_target,\n",
    "                      environment=pytorch_env)\n",
    "    \n",
    "    train_step = CommandStep(name='train-step', runconfig=train_config)\n",
    "    \n",
    "    return train_step, outputs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = ScriptRunConfig(source_directory=os.path.dirname(os.path.abspath(__file__),\n",
    "    script='train.py',arguments=['--num_epochs', 30, '--output_dir', './outputs',  '--train_dir', train_dir, \n",
    "                                      '--valid_dir', valid_dir, \n",
    "                                      '--output_dir', model_dir, \n",
    "                                      '--num_epochs', num_epochs, \n",
    "                                      '--batch_size', batch_size,\n",
    "                                      '--learning_rate', learning_rate, \n",
    "                                      '--momentum', momentum\n",
    "                                    ],\n",
    "                                    compute_target=compute_target,\n",
    "                                    environment=pytorch_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{\n",
       "  \"name\": \"workspaceblobstore\",\n",
       "  \"container_name\": \"azureml-blobstore-b66b1b52-c2d7-4600-8c2e-8051b69239cc\",\n",
       "  \"account_name\": \"mlservice7009088601\",\n",
       "  \"protocol\": \"https\",\n",
       "  \"endpoint\": \"core.windows.net\"\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "workspace = Workspace.from_config()\n",
    "datastore = workspace.get_default_datastore()\n",
    "datastore"
   ]
  }
 ]
}