{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('aml': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a5d4df4a22655ddcd3995113ae21abdf5e3f153b58eb8770b042525e3ea05670"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Connecting to Workspace ...\n",
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.data.data_reference import DataReference\n",
    "from modules.ingestion.data_ingestion_step import data_ingestion_step\n",
    "from modules.preprocess.data_preprocess_step import data_preprocess_step\n",
    "from modules.train.train_step import train_step\n",
    "from modules.evaluate.evaluate_step import evaluate_step\n",
    "from modules.deploy.deploy_step import deploy_step\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "# Get workspace, datastores, and compute targets\n",
    "print('Connecting to Workspace ...')\n",
    "workspace = Workspace.from_config()\n",
    "datastore = workspace.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating CPU compute target ...\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# Create CPU compute target\n",
    "print('Creating CPU compute target ...')\n",
    "cpu_cluster_name = 'ds3cluster'\n",
    "cpu_compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS3_V2', \n",
    "                                                           idle_seconds_before_scaledown=1200,\n",
    "                                                           min_nodes=0, \n",
    "                                                           max_nodes=2)\n",
    "cpu_compute_target = ComputeTarget.create(workspace, cpu_cluster_name, cpu_compute_config)\n",
    "cpu_compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating GPU compute target ...\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# Create GPU compute target\n",
    "print('Creating GPU compute target ...')\n",
    "gpu_cluster_name = 'k80cluster'\n",
    "gpu_compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC6', \n",
    "                                                           idle_seconds_before_scaledown=1200,\n",
    "                                                           min_nodes=0, \n",
    "                                                           max_nodes=2)\n",
    "gpu_compute_target = ComputeTarget.create(workspace, gpu_cluster_name, gpu_compute_config)\n",
    "gpu_compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get datastore reference\n",
    "datastore = DataReference(datastore, mode='mount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data ingestion \n",
    "data_ingestion_step, data_ingestion_outputs = data_ingestion_step(datastore, cpu_compute_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data preprocessing \n",
    "data_preprocess_step, data_preprocess_outputs = data_preprocess_step(data_ingestion_outputs['raw_data_dir'], cpu_compute_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train Model\n",
    "train_step, train_outputs = train_step(data_preprocess_outputs['train_dir'], data_preprocess_outputs['valid_dir'], gpu_compute_target, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Evaluate Model\n",
    "evaluate_step, evaluate_outputs = evaluate_step(train_outputs['model_dir'], data_preprocess_outputs['test_dir'], gpu_compute_target, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Deploy Model\n",
    "deploy_step, deploy_outputs = deploy_step(train_outputs['model_dir'], evaluate_outputs['accuracy_file'], data_preprocess_outputs['test_dir'], cpu_compute_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Submitting pipeline ...\n",
      "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n",
      "Created step data_ingestion.py [26474016][5c5ddd07-983a-49f6-ba92-6ccbf6c1c529], (This step is eligible to reuse a previous run's output)\n",
      "Created step data_preprocess.py [4744b5ed][9c731824-6d68-4901-840a-ffc9fe6bf0d2], (This step is eligible to reuse a previous run's output)\n",
      "Created step train-step [51603ddb][13405cbd-870e-41d6-95a5-8b0563d0f06c], (This step is eligible to reuse a previous run's output)\n",
      "Created step evaulate-step [fa726159][c8236d51-3a55-4e9e-8c13-b2bd039c0957], (This step is eligible to reuse a previous run's output)\n",
      "Created step deploy.py [f782bdf3][fd37d7ec-0741-442e-b723-15724d031cde], (This step will run and generate new outputs)\n",
      "Using data reference workspaceblobstore for StepId [9a1bf7a1][2e9aceb1-5642-47cb-8b85-c04af5d94de2], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted PipelineRun 474de950-c3f3-4bb4-a0a1-73492e94431e\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/474de950-c3f3-4bb4-a0a1-73492e94431e?wsid=/subscriptions/3e0e14b3-7e28-4da7-97de-0f5cb324f030/resourcegroups/ml/workspaces/ml-service&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "# Submit pipeline\n",
    "print('Submitting pipeline ...')\n",
    "pipeline_parameters = {\n",
    "    'num_images': 100,\n",
    "    'image_dim': 200,\n",
    "    'num_epochs': 10, \n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 0.001, \n",
    "    'momentum': 0.9\n",
    "}\n",
    "pipeline = Pipeline(workspace=workspace, steps=[data_ingestion_step, data_preprocess_step, train_step, evaluate_step, deploy_step])\n",
    "pipeline_run = Experiment(workspace, 'object-recognition-pipeline').submit(pipeline, pipeline_parameters=pipeline_parameters)\n"
   ]
  }
 ]
}