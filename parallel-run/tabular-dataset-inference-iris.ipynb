{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.25.0\n"
          ]
        }
      ],
      "source": [
        "# Check core SDK version number\n",
        "import azureml.core\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Falling back to use azure cli login credentials.\n",
            "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
            "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n",
            "Workspace name: ml-service\n",
            "Azure region: westus2\n",
            "Subscription id: 3e0e14b3-7e28-4da7-97de-0f5cb324f030\n",
            "Resource group: ml\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create or Attach existing compute resource\n",
        "By using Azure Machine Learning Compute, a managed service, data scientists can train machine learning models on clusters of Azure virtual machines. Examples include VMs with GPU support. In this tutorial, you create Azure Machine Learning Compute as your training environment. The code below creates the compute clusters for you if they don't already exist in your workspace.\n",
        "\n",
        "**Creation of compute takes approximately 5 minutes. If the AmlCompute with that name is already in your workspace the code will skip the creation process.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found compute target. just use it. ds3cluster\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from azureml.core.compute import AmlCompute, ComputeTarget\n",
        "\n",
        "# choose a name for your cluster\n",
        "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"ds3cluster\")\n",
        "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
        "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 2)\n",
        "\n",
        "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
        "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
        "\n",
        "\n",
        "if compute_name in ws.compute_targets:\n",
        "    compute_target = ws.compute_targets[compute_name]\n",
        "    if compute_target and type(compute_target) is AmlCompute:\n",
        "        print('found compute target. just use it. ' + compute_name)\n",
        "else:\n",
        "    print('creating a new compute target...')\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
        "                                                                min_nodes = compute_min_nodes, \n",
        "                                                                max_nodes = compute_max_nodes)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
        "    \n",
        "    # can poll for a minimum number of nodes and for a specific timeout.\n",
        "    # if no min node count is provided it will use the scale settings for the cluster\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "    \n",
        "     # For a more detailed view of current AmlCompute status, use get_status()\n",
        "    print(compute_target.get_status().serialize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a datastore containing sample images\n",
        "The input dataset used for this notebook is CSV data which has attributes of different iris flowers. We have created a public blob container `sampledata` on an account named `pipelinedata`, containing iris data set. In the next step, we create a datastore with the name `iris_datastore`, which points to this container. In the call to `register_azure_blob_container` below, setting the `overwrite` flag to `True` overwrites any datastore that was created previously with that name. \n",
        "\n",
        "This step can be changed to point to your blob container by providing your own `datastore_name`, `container_name`, and `account_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.datastore import Datastore\n",
        "\n",
        "account_name = \"pipelinedata\"\n",
        "datastore_name=\"iris_datastore_data\"\n",
        "container_name=\"sampledata\"\n",
        "\n",
        "iris_data = Datastore.register_azure_blob_container(ws, \n",
        "                      datastore_name=datastore_name, \n",
        "                      container_name= container_name, \n",
        "                      account_name=account_name, \n",
        "                      overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a TabularDataset\n",
        "A [TabularDataSet](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.tabulardataset?view=azure-ml-py) references single or multiple files which contain data in a tabular structure (ie like CSV files) in your datastores or public urls. TabularDatasets provides you with the ability to download or mount the files to your compute. By creating a dataset, you create a reference to the data source location. If you applied any subsetting transformations to the dataset, they will be stored in the dataset as well. The data remains in its existing location, so no extra storage cost is incurred.\n",
        "You can use dataset objects as inputs. Register the datasets to the workspace if you want to reuse them later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "iris_ds_name = 'iris_data'\n",
        "\n",
        "path_on_datastore = iris_data.path('iris/')\n",
        "input_iris_ds = Dataset.Tabular.from_delimited_files(path=path_on_datastore, validate=False)\n",
        "named_iris_ds = input_iris_ds.as_named_input(iris_ds_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Intermediate/Output Data\n",
        "Intermediate data (or output of a Step) is represented by [PipelineData](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipelinedata?view=azure-ml-py) object. PipelineData can be produced by one step and consumed in another step by providing the PipelineData object as an output of one step and the input of one or more steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import PipelineData\n",
        "\n",
        "datastore = ws.get_default_datastore()\n",
        "output_folder = PipelineData(name='inferences', datastore=datastore)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Registering the Model with the Workspace\n",
        "Get the pretrained model from a publicly available Azure Blob container, then register it to use in your workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_container_name=\"iris-model\"\n",
        "model_datastore_name=\"iris_model_datastore\"\n",
        "\n",
        "model_datastore = Datastore.register_azure_blob_container(ws, \n",
        "                      datastore_name=model_datastore_name, \n",
        "                      container_name= model_container_name, \n",
        "                      account_name=account_name, \n",
        "                      overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading iris_model.pkl/iris_model.pkl\n",
            "Downloaded iris_model.pkl/iris_model.pkl, 1 files out of an estimated total of 1\n",
            "Registering model iris-prs\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.model import Model\n",
        "\n",
        "model_datastore.download('iris_model.pkl')\n",
        "\n",
        "# register downloaded model\n",
        "model = Model.register(model_path = \"iris_model.pkl/iris_model.pkl\",\n",
        "                       model_name = \"iris-prs\", # this is the name the model is registered as\n",
        "                       tags = {'pretrained': \"iris\"},\n",
        "                       workspace = ws)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using your model to make batch predictions\n",
        "To use the model to make batch predictions, you need an **entry script** and a list of **dependencies**:\n",
        "\n",
        "#### An entry script\n",
        "This script accepts requests, scores the requests by using the model, and returns the results.\n",
        "- __init()__ - Typically this function loads the model into a global object. This function is run only once at the start of batch processing per worker node/process. init method can make use of following environment variables (ParallelRunStep input):\n",
        "    1.\tAZUREML_BI_OUTPUT_PATH â€“ output folder path\n",
        "- __run(mini_batch)__ - The method to be parallelized. Each invocation will have one minibatch.<BR>\n",
        "__mini_batch__: Batch inference will invoke run method and pass either a list or Pandas DataFrame as an argument to the method. Each entry in min_batch will be - a filepath if input is a FileDataset, a Pandas DataFrame if input is a TabularDataset.<BR>\n",
        "__run__ method response: run() method should return a Pandas DataFrame or an array. For append_row output_action, these returned elements are appended into the common output file. For summary_only, the contents of the elements are ignored. For all output actions, each returned output element indicates one successful inference of input element in the input mini-batch.\n",
        "    User should make sure that enough data is included in inference result to map input to inference. Inference output will be written in output file and not guaranteed to be in order, user should use some key in the output to map it to input.\n",
        "    \n",
        "\n",
        "#### Dependencies\n",
        "Helper scripts or Python/Conda packages required to run the entry script.\n",
        "\n",
        "## Print inferencing script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import io\nimport pickle\nimport argparse\nimport numpy as np\n\nfrom azureml.core.model import Model\nfrom sklearn.linear_model import LogisticRegression\n\nfrom azureml_user.parallel_run import EntryScript\n\n\ndef init():\n    global iris_model\n\n    logger = EntryScript().logger\n    logger.info(\"init() is called.\")\n\n    parser = argparse.ArgumentParser(description=\"Iris model serving\")\n    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n    args, unknown_args = parser.parse_known_args()\n\n    model_path = Model.get_model_path(args.model_name)\n    with open(model_path, 'rb') as model_file:\n        iris_model = pickle.load(model_file)\n\n\ndef run(input_data):\n    logger = EntryScript().logger\n    logger.info(\"run() is called with: {}.\".format(input_data))\n\n    # make inference\n    num_rows, num_cols = input_data.shape\n    pred = iris_model.predict(input_data).reshape((num_rows, 1))\n\n    # cleanup output\n    result = input_data.drop(input_data.columns[4:], axis=1)\n    result['variety'] = pred\n\n    return result\n\n"
          ]
        }
      ],
      "source": [
        "scripts_folder = \"Code\"\n",
        "script_file = \"iris_score.py\"\n",
        "\n",
        "# peek at contents\n",
        "with open(os.path.join(scripts_folder, script_file)) as inference_file:\n",
        "    print(inference_file.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build and run the batch inference pipeline\n",
        "The data, models, and compute resource are now available. Let's put all these together in a pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Specify the environment to run the script\n",
        "Specify the conda dependencies for your script. This will allow us to install pip packages as well as configure the inference environment.\n",
        "* Always include **azureml-core** and **azureml-dataset-runtime\\[fuse\\]** in the pip package list to make ParallelRunStep run properly.\n",
        "* For TabularDataset, add **pandas** as `run(mini_batch)` uses `pandas.DataFrame` as mini_batch type.\n",
        "\n",
        "If you're using custom image (`batch_env.python.user_managed_dependencies = True`), you need to install the package to your image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.runconfig import CondaDependencies\n",
        "\n",
        "predict_conda_deps = CondaDependencies.create(pip_packages=[\"scikit-learn==0.20.3\",\n",
        "                                                            \"azureml-core\", \"azureml-dataset-runtime[pandas,fuse]\"])\n",
        "\n",
        "predict_env = Environment(name=\"predict_environment\")\n",
        "predict_env.python.conda_dependencies = predict_conda_deps\n",
        "predict_env.docker.enabled = True\n",
        "predict_env.spark.precache_packages = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Create the configuration to wrap the inference script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.pipeline.steps import ParallelRunStep, ParallelRunConfig\n",
        "\n",
        "# In a real-world scenario, you'll want to shape your process per node and nodes to fit your problem domain.\n",
        "parallel_run_config = ParallelRunConfig(\n",
        "    source_directory=scripts_folder,\n",
        "    entry_script=script_file,  # the user script to run against each input\n",
        "    mini_batch_size='1KB',\n",
        "    error_threshold=5,\n",
        "    output_action='append_row',\n",
        "    append_row_file_name=\"iris_outputs.txt\",\n",
        "    environment=predict_env,\n",
        "    compute_target=compute_target, \n",
        "    node_count=2,\n",
        "    run_invocation_timeout=600\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create the pipeline step\n",
        "Create the pipeline step using the script, environment configuration, and parameters. Specify the compute target you already attached to your workspace as the target of execution of the script. We will use ParallelRunStep to create the pipeline step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
          ]
        }
      ],
      "source": [
        "distributed_csv_iris_step = ParallelRunStep(\n",
        "    name='example-iris',\n",
        "    inputs=[named_iris_ds],\n",
        "    output=output_folder,\n",
        "    parallel_run_config=parallel_run_config,\n",
        "    arguments=['--model_name', 'iris-prs'],\n",
        "    allow_reuse=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the pipeline\n",
        "At this point you can run the pipeline and examine the output it produced. The Experiment object is used to track the run of the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created step example-iris [6be526d3][4e7b9b06-2ad2-48d3-b044-05cd51e40b13], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun 7ee258d4-451c-4c27-88e7-e8c97a71e276\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/7ee258d4-451c-4c27-88e7-e8c97a71e276?wsid=/subscriptions/3e0e14b3-7e28-4da7-97de-0f5cb324f030/resourcegroups/ml/workspaces/ml-service&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import Pipeline\n",
        "\n",
        "pipeline = Pipeline(workspace=ws, steps=[distributed_csv_iris_step])\n",
        "\n",
        "pipeline_run = Experiment(ws, 'iris-prs').submit(pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View progress of Pipeline run\n",
        "\n",
        "The pipeline run status could be checked in Azure Machine Learning portal (https://ml.azure.com). The link to the pipeline run could be retrieved by inspecting the `pipeline_run` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Run(Experiment: iris-prs,\n",
              "Id: 7ee258d4-451c-4c27-88e7-e8c97a71e276,\n",
              "Type: azureml.PipelineRun,\n",
              "Status: Preparing)"
            ],
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>iris-prs</td><td>7ee258d4-451c-4c27-88e7-e8c97a71e276</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/7ee258d4-451c-4c27-88e7-e8c97a71e276?wsid=/subscriptions/3e0e14b3-7e28-4da7-97de-0f5cb324f030/resourcegroups/ml/workspaces/ml-service&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# This will output information of the pipeline run, including the link to the details page of portal.\n",
        "pipeline_run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: View detailed logs (streaming) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineRunId: 7ee258d4-451c-4c27-88e7-e8c97a71e276\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/7ee258d4-451c-4c27-88e7-e8c97a71e276?wsid=/subscriptions/3e0e14b3-7e28-4da7-97de-0f5cb324f030/resourcegroups/ml/workspaces/ml-service&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: 977a5778-f7ff-47d8-bc0b-be5b056d3032\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/977a5778-f7ff-47d8-bc0b-be5b056d3032?wsid=/subscriptions/3e0e14b3-7e28-4da7-97de-0f5cb324f030/resourcegroups/ml/workspaces/ml-service&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "StepRun( example-iris ) Status: NotStarted\n",
            "StepRun( example-iris ) Status: Queued\n",
            "StepRun( example-iris ) Status: Running\n",
            "\n",
            "Streaming azureml-logs/20_image_build_log.txt\n",
            "=============================================\n",
            "2021/03/29 09:19:06 Downloading source code...\n",
            "2021/03/29 09:19:07 Finished downloading source code\n",
            "2021/03/29 09:19:08 Creating Docker network: acb_default_network, driver: 'bridge'\n",
            "2021/03/29 09:19:08 Successfully set up Docker network: acb_default_network\n",
            "2021/03/29 09:19:08 Setting up Docker configuration...\n",
            "2021/03/29 09:19:09 Successfully set up Docker configuration\n",
            "2021/03/29 09:19:09 Logging in to registry: mlservice1724bc10.azurecr.io\n",
            "2021/03/29 09:19:10 Successfully logged into mlservice1724bc10.azurecr.io\n",
            "2021/03/29 09:19:10 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/03/29 09:19:10 Scanning for dependencies...\n",
            "2021/03/29 09:19:11 Successfully scanned dependencies\n",
            "2021/03/29 09:19:11 Launching container with name: acb_step_0\n",
            "Sending build context to Docker daemon  66.56kB\n",
            "\n",
            "Step 1/17 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1@sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            "sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df: Pulling from azureml/intelmpi2018.3-ubuntu16.04\n",
            "Digest: sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            "Status: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1@sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            " ---> c942df5ba5d0\n",
            "Step 2/17 : USER root\n",
            " ---> Running in 5e7e2afc5312\n",
            "Removing intermediate container 5e7e2afc5312\n",
            " ---> 8f488cc647b1\n",
            "Step 3/17 : RUN mkdir -p $HOME/.cache\n",
            " ---> Running in 13007e39b5bc\n",
            "Removing intermediate container 13007e39b5bc\n",
            " ---> dc95956a6a3c\n",
            "Step 4/17 : WORKDIR /\n",
            " ---> Running in 68f8e0164cc0\n",
            "Removing intermediate container 68f8e0164cc0\n",
            " ---> 239d6cdfbb19\n",
            "Step 5/17 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
            " ---> b4157f15ab81\n",
            "Step 6/17 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
            " ---> Running in dd0d71eee899\n",
            "Removing intermediate container dd0d71eee899\n",
            " ---> 75804c8f405d\n",
            "Step 7/17 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
            " ---> c89957b66c78\n",
            "Step 8/17 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_695c788487209be000aba32be44fc97b -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
            " ---> Running in f14d30bd6190\n",
            "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
            "Collecting package metadata (repodata.json): ...working... \n",
            "done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "ca-certificates-2020 | 128 KB    |            |   0% \n",
            "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
            "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
            "\n",
            "libedit-3.1          | 171 KB    |            |   0% \n",
            "libedit-3.1          | 171 KB    | ########## | 100% \n",
            "\n",
            "certifi-2020.6.20    | 160 KB    |            |   0% \n",
            "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
            "\n",
            "libffi-3.2.1         | 52 KB     |            |   0% \n",
            "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
            "\n",
            "python-3.6.2         | 27.0 MB   |            |   0% \n",
            "python-3.6.2         | 27.0 MB   | ##2        |  23% \n",
            "python-3.6.2         | 27.0 MB   | #####8     |  59% \n",
            "python-3.6.2         | 27.0 MB   | ########1  |  82% \n",
            "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
            "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
            "\n",
            "zlib-1.2.11          | 120 KB    |            |   0% \n",
            "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
            "\n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
            "\n",
            "tk-8.6.10            | 3.2 MB    |            |   0% \n",
            "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
            "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
            "\n",
            "setuptools-50.3.0    | 891 KB    |            |   0% \n",
            "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
            "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
            "\n",
            "pip-20.2.4           | 2.0 MB    |            |   0% \n",
            "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
            "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
            "\n",
            "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
            "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
            "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
            "\n",
            "wheel-0.35.1         | 36 KB     |            |   0% \n",
            "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
            "\n",
            "readline-7.0         | 387 KB    |            |   0% \n",
            "readline-7.0         | 387 KB    | ########## | 100% \n",
            "readline-7.0         | 387 KB    | ########## | 100% \n",
            "\n",
            "ncurses-6.0          | 907 KB    |            |   0% \n",
            "ncurses-6.0          | 907 KB    | ########## | 100% \n",
            "ncurses-6.0          | 907 KB    | ########## | 100% \n",
            "\n",
            "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
            "libgcc-ng-9.1.0      | 8.1 MB    | ########8  |  88% \n",
            "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
            "\n",
            "xz-5.2.5             | 438 KB    |            |   0% \n",
            "xz-5.2.5             | 438 KB    | ########## | 100% \n",
            "xz-5.2.5             | 438 KB    | ########## | 100% \n",
            "\n",
            "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
            "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
            "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Installing pip dependencies: ...working... \n",
            "Ran pip subprocess with arguments:\n",
            "['/azureml-envs/azureml_695c788487209be000aba32be44fc97b/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.q0z3t7fj.requirements.txt']\n",
            "Pip subprocess output:\n",
            "Collecting scikit-learn==0.20.3\n",
            "  Downloading scikit_learn-0.20.3-cp36-cp36m-manylinux1_x86_64.whl (5.4 MB)\n",
            "Collecting azureml-core~=1.25.0\n",
            "  Downloading azureml_core-1.25.0-py3-none-any.whl (2.2 MB)\n",
            "Collecting azureml-dataset-runtime[fuse,pandas]~=1.25.0\n",
            "  Downloading azureml_dataset_runtime-1.25.0-py3-none-any.whl (3.4 kB)\n",
            "Collecting scipy>=0.13.3\n",
            "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
            "Collecting numpy>=1.8.2\n",
            "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "Collecting contextlib2\n",
            "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting ndg-httpsclient\n",
            "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
            "Collecting jmespath\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting pathspec\n",
            "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
            "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
            "  Downloading azure_mgmt_resource-12.1.0-py2.py3-none-any.whl (1.1 MB)\n",
            "Collecting azure-common>=1.1.12\n",
            "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
            "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
            "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
            "Collecting pyopenssl<21.0.0\n",
            "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
            "Collecting msrest>=0.5.1\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n",
            "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
            "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
            "Collecting docker\n",
            "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
            "Collecting pytz\n",
            "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
            "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
            "Collecting urllib3>=1.23\n",
            "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
            "Collecting ruamel.yaml>=0.15.35\n",
            "  Downloading ruamel.yaml-0.17.0-py2.py3-none-any.whl (101 kB)\n",
            "Collecting backports.tempfile\n",
            "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting PyJWT<3.0.0\n",
            "  Downloading PyJWT-2.0.1-py3-none-any.whl (15 kB)\n",
            "Collecting requests<3.0.0,>=2.19.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "Collecting msrestazure>=0.4.33\n",
            "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
            "Collecting azure-mgmt-containerregistry>=2.0.0\n",
            "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
            "Collecting python-dateutil>=2.7.3\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "Collecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting SecretStorage\n",
            "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
            "Collecting adal>=1.2.0\n",
            "  Downloading adal-1.2.6-py2.py3-none-any.whl (55 kB)\n",
            "Collecting azureml-dataprep<2.12.0a,>=2.11.0a\n",
            "  Downloading azureml_dataprep-2.11.2-py3-none-any.whl (39.4 MB)\n",
            "Collecting pyarrow<2.0.0,>=0.17.0\n",
            "  Downloading pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3 MB)\n",
            "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
            "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
            "Collecting pandas<2.0.0,>=0.23.4; extra == \"pandas\"\n",
            "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
            "Collecting pyasn1>=0.1.1\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Collecting six>=1.5.2\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "Collecting requests-oauthlib>=0.5.0\n",
            "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_695c788487209be000aba32be44fc97b/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core~=1.25.0->-r /azureml-environment-setup/condaenv.q0z3t7fj.requirements.txt (line 2)) (2020.6.20)\n",
            "Collecting cffi>=1.12\n",
            "  Downloading cffi-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-0.58.0-py2.py3-none-any.whl (61 kB)\n",
            "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n",
            "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
            "Collecting backports.weakref\n",
            "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
            "Collecting chardet<5,>=3.0.2\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "Collecting idna<3,>=2.5\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "Collecting importlib-metadata; python_version < \"3.8\"\n",
            "  Downloading importlib_metadata-3.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting jeepney>=0.6\n",
            "  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\n",
            "Collecting azure-identity<1.5.0,>=1.2.0\n",
            "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
            "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
            "  Downloading dotnetcore2-2.1.20-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
            "Collecting azureml-dataprep-native<31.0.0,>=30.0.0\n",
            "  Downloading azureml_dataprep_native-30.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
            "Collecting azureml-dataprep-rslex<1.10.0a,>=1.9.0dev0\n",
            "  Downloading azureml_dataprep_rslex-1.9.1-cp36-cp36m-manylinux2010_x86_64.whl (9.0 MB)\n",
            "Collecting cloudpickle<2.0.0,>=1.1.0\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
            "Collecting pycparser\n",
            "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
            "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting msal<2.0.0,>=1.3.0\n",
            "  Downloading msal-1.10.0-py2.py3-none-any.whl (60 kB)\n",
            "Collecting msal-extensions~=0.2.2\n",
            "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
            "Collecting azure-core<2.0.0,>=1.0.0\n",
            "  Downloading azure_core-1.12.0-py2.py3-none-any.whl (130 kB)\n",
            "Collecting distro>=1.2.0\n",
            "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting portalocker~=1.0; platform_system != \"Windows\"\n",
            "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: fusepy\n",
            "  Building wheel for fusepy (setup.py): started\n",
            "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
            "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=ad69d10fb85710f5c8564c91cded6517b5d685b082fc7fccd9c6698cf14c87a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
            "Successfully built fusepy\n",
            "Installing collected packages: numpy, scipy, scikit-learn, contextlib2, pycparser, cffi, cryptography, six, pyopenssl, pyasn1, ndg-httpsclient, jmespath, pathspec, isodate, chardet, urllib3, idna, requests, oauthlib, requests-oauthlib, msrest, python-dateutil, PyJWT, adal, msrestazure, azure-common, azure-mgmt-resource, azure-mgmt-storage, azure-graphrbac, websocket-client, docker, pytz, azure-mgmt-authorization, ruamel.yaml.clib, ruamel.yaml, backports.weakref, backports.tempfile, azure-mgmt-containerregistry, azure-mgmt-keyvault, zipp, typing-extensions, importlib-metadata, jsonpickle, jeepney, SecretStorage, azureml-core, msal, portalocker, msal-extensions, azure-core, azure-identity, distro, dotnetcore2, azureml-dataprep-native, azureml-dataprep-rslex, cloudpickle, azureml-dataprep, pyarrow, fusepy, pandas, azureml-dataset-runtime\n",
            "Successfully installed PyJWT-2.0.1 SecretStorage-3.3.1 adal-1.2.6 azure-common-1.1.27 azure-core-1.12.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-12.1.0 azure-mgmt-storage-11.2.0 azureml-core-1.25.0 azureml-dataprep-2.11.2 azureml-dataprep-native-30.0.0 azureml-dataprep-rslex-1.9.1 azureml-dataset-runtime-1.25.0 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.5 chardet-4.0.0 cloudpickle-1.6.0 contextlib2-0.6.0.post1 cryptography-3.4.7 distro-1.5.0 docker-4.4.4 dotnetcore2-2.1.20 fusepy-3.0.1 idna-2.10 importlib-metadata-3.9.0 isodate-0.6.0 jeepney-0.6.0 jmespath-0.10.0 jsonpickle-2.0.0 msal-1.10.0 msal-extensions-0.2.2 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.19.5 oauthlib-3.1.0 pandas-1.1.5 pathspec-0.8.1 portalocker-1.7.1 pyarrow-1.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-20.0.1 python-dateutil-2.8.1 pytz-2021.1 requests-2.25.1 requests-oauthlib-1.3.0 ruamel.yaml-0.17.0 ruamel.yaml.clib-0.2.2 scikit-learn-0.20.3 scipy-1.5.4 six-1.15.0 typing-extensions-3.7.4.3 urllib3-1.26.4 websocket-client-0.58.0 zipp-3.4.1\n",
            "\n",
            "done\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate /azureml-envs/azureml_695c788487209be000aba32be44fc97b\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "WARNING: /root/.conda/pkgs does not exist\n",
            "Removing intermediate container f14d30bd6190\n",
            " ---> 614b660a3bc8\n",
            "Step 9/17 : ENV PATH /azureml-envs/azureml_695c788487209be000aba32be44fc97b/bin:$PATH\n",
            " ---> Running in b6b2e16ee5aa\n",
            "Removing intermediate container b6b2e16ee5aa\n",
            " ---> 5ebd0725e706\n",
            "Step 10/17 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
            " ---> 248712b483e6\n",
            "Step 11/17 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
            " ---> 00e71d98802a\n",
            "Step 12/17 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_695c788487209be000aba32be44fc97b\n",
            " ---> Running in 13585d64d2d3\n",
            "Report materialized dependencies for the environment\n",
            "Reading environment context\n",
            "Exporting conda environment\n",
            "Sending request with materialized conda environment details\n",
            "Successfully sent materialized environment details\n",
            "Removing intermediate container 13585d64d2d3\n",
            " ---> b947ac072076\n",
            "Step 13/17 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_695c788487209be000aba32be44fc97b\n",
            " ---> Running in 9ea4c011205d\n",
            "Removing intermediate container 9ea4c011205d\n",
            " ---> 8daa38cbb66a\n",
            "Step 14/17 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_695c788487209be000aba32be44fc97b/lib:$LD_LIBRARY_PATH\n",
            " ---> Running in e4cc4c3e7f52\n",
            "Removing intermediate container e4cc4c3e7f52\n",
            " ---> 6d2a73348f92\n",
            "Step 15/17 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
            " ---> 1fc582db4e34\n",
            "Step 16/17 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
            " ---> Running in 0d1fc9c37c31\n",
            "Removing intermediate container 0d1fc9c37c31\n",
            " ---> 5a397290da7c\n",
            "Step 17/17 : CMD [\"bash\"]\n",
            " ---> Running in 8f8f24aa68f1\n",
            "Removing intermediate container 8f8f24aa68f1\n",
            " ---> c60c60f3fe16\n",
            "Successfully built c60c60f3fe16\n",
            "Successfully tagged mlservice1724bc10.azurecr.io/azureml/azureml_18ce9a15f9167f04bc822d43230f7564:latest\n",
            "Successfully tagged mlservice1724bc10.azurecr.io/azureml/azureml_18ce9a15f9167f04bc822d43230f7564:1\n",
            "2021/03/29 09:21:48 Successfully executed container: acb_step_0\n",
            "2021/03/29 09:21:48 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/03/29 09:21:48 Pushing image: mlservice1724bc10.azurecr.io/azureml/azureml_18ce9a15f9167f04bc822d43230f7564:1, attempt 1\n",
            "The push refers to repository [mlservice1724bc10.azurecr.io/azureml/azureml_18ce9a15f9167f04bc822d43230f7564]\n",
            "d1577c3cf528: Preparing\n",
            "c1d8cc3618c6: Preparing\n",
            "ff31e2dd4424: Preparing\n",
            "1b6aadfc1ce1: Preparing\n",
            "75e8c21f0c2d: Preparing\n",
            "3f428fb66df0: Preparing\n",
            "01ddedc586a9: Preparing\n",
            "2aaa7d7a43ec: Preparing\n",
            "ebc9c0e5f8a0: Preparing\n",
            "3f3f8889d538: Preparing\n",
            "420340de7040: Preparing\n",
            "c3d9b0d7dd4c: Preparing\n",
            "4441896e1280: Preparing\n",
            "a64fe594a899: Preparing\n",
            "0d34930f20d5: Preparing\n",
            "18c9012f327d: Preparing\n",
            "e4a0bf630548: Preparing\n",
            "5276d2b930fc: Preparing\n",
            "e6feec0db89a: Preparing\n",
            "697949baa658: Preparing\n",
            "935c56d8b3f9: Preparing\n",
            "c3d9b0d7dd4c: Waiting\n",
            "4441896e1280: Waiting\n",
            "a64fe594a899: Waiting\n",
            "0d34930f20d5: Waiting\n",
            "18c9012f327d: Waiting\n",
            "e4a0bf630548: Waiting\n",
            "5276d2b930fc: Waiting\n",
            "e6feec0db89a: Waiting\n",
            "935c56d8b3f9: Waiting\n",
            "697949baa658: Waiting\n",
            "2aaa7d7a43ec: Waiting\n",
            "ebc9c0e5f8a0: Waiting\n",
            "3f3f8889d538: Waiting\n",
            "420340de7040: Waiting\n",
            "3f428fb66df0: Waiting\n",
            "01ddedc586a9: Waiting\n",
            "1b6aadfc1ce1: Pushed\n",
            "ff31e2dd4424: Pushed\n",
            "d1577c3cf528: Pushed\n",
            "c1d8cc3618c6: Pushed\n",
            "3f428fb66df0: Pushed\n",
            "01ddedc586a9: Pushed\n",
            "2aaa7d7a43ec: Pushed\n",
            "ebc9c0e5f8a0: Pushed\n",
            "3f3f8889d538: Pushed\n",
            "420340de7040: Pushed\n",
            "c3d9b0d7dd4c: Pushed\n",
            "18c9012f327d: Pushed\n",
            "4441896e1280: Pushed\n",
            "0d34930f20d5: Pushed\n",
            "5276d2b930fc: Pushed\n",
            "e6feec0db89a: Pushed\n",
            "697949baa658: Pushed\n",
            "a64fe594a899: Pushed\n",
            "935c56d8b3f9: Pushed\n",
            "e4a0bf630548: Pushed\n",
            "75e8c21f0c2d: Pushed\n",
            "1: digest: sha256:31d81ed9ba79f8fadbad81b585d1c7b0a3af61ff53b1f66a471c22ace5fa658a size: 4721\n",
            "2021/03/29 09:23:34 Successfully pushed image: mlservice1724bc10.azurecr.io/azureml/azureml_18ce9a15f9167f04bc822d43230f7564:1\n",
            "2021/03/29 09:23:34 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/03/29 09:23:34 Pushing image: mlservice1724bc10.azurecr.io/azureml/azureml_18ce9a15f9167f04bc822d43230f7564:latest, attempt 1\n",
            "The push refers to repository [mlservice1724bc10.azurecr.io/azureml/azureml_18ce9a15f9167f04bc822d43230f7564]\n",
            "d1577c3cf528: Preparing\n",
            "c1d8cc3618c6: Preparing\n",
            "ff31e2dd4424: Preparing\n",
            "1b6aadfc1ce1: Preparing\n",
            "75e8c21f0c2d: Preparing\n",
            "3f428fb66df0: Preparing\n",
            "01ddedc586a9: Preparing\n",
            "2aaa7d7a43ec: Preparing\n",
            "ebc9c0e5f8a0: Preparing\n",
            "3f3f8889d538: Preparing\n",
            "420340de7040: Preparing\n",
            "c3d9b0d7dd4c: Preparing\n",
            "4441896e1280: Preparing\n",
            "a64fe594a899: Preparing\n",
            "0d34930f20d5: Preparing\n",
            "18c9012f327d: Preparing\n",
            "e4a0bf630548: Preparing\n",
            "5276d2b930fc: Preparing\n",
            "e6feec0db89a: Preparing\n",
            "697949baa658: Preparing\n",
            "935c56d8b3f9: Preparing\n",
            "4441896e1280: Waiting\n",
            "a64fe594a899: Waiting\n",
            "0d34930f20d5: Waiting\n",
            "3f428fb66df0: Waiting\n",
            "18c9012f327d: Waiting\n",
            "01ddedc586a9: Waiting\n",
            "e4a0bf630548: Waiting\n",
            "2aaa7d7a43ec: Waiting\n",
            "ebc9c0e5f8a0: Waiting\n",
            "5276d2b930fc: Waiting\n",
            "3f3f8889d538: Waiting\n",
            "e6feec0db89a: Waiting\n",
            "697949baa658: Waiting\n",
            "935c56d8b3f9: Waiting\n",
            "c3d9b0d7dd4c: Waiting\n",
            "420340de7040: Waiting\n",
            "1b6aadfc1ce1: Layer already exists\n",
            "ff31e2dd4424: Layer already exists\n",
            "c1d8cc3618c6: Layer already exists\n",
            "d1577c3cf528: Layer already exists\n",
            "75e8c21f0c2d: Layer already exists\n",
            "2aaa7d7a43ec: Layer already exists\n",
            "01ddedc586a9: Layer already exists\n",
            "3f428fb66df0: Layer already exists\n",
            "ebc9c0e5f8a0: Layer already exists\n",
            "420340de7040: Layer already exists\n",
            "a64fe594a899: Layer already exists\n",
            "3f3f8889d538: Layer already exists\n",
            "0d34930f20d5: Layer already exists\n",
            "18c9012f327d: Layer already exists\n",
            "c3d9b0d7dd4c: Layer already exists\n",
            "5276d2b930fc: Layer already exists\n",
            "e6feec0db89a: Layer already exists\n",
            "4441896e1280: Layer already exists\n",
            "935c56d8b3f9: Layer already exists\n",
            "e4a0bf630548: Layer already exists\n",
            "697949baa658: Layer already exists\n",
            "latest: digest: sha256:31d81ed9ba79f8fadbad81b585d1c7b0a3af61ff53b1f66a471c22ace5fa658a size: 4721\n",
            "2021/03/29 09:23:36 Successfully pushed image: mlservice1724bc10.azurecr.io/azureml/azureml_18ce9a15f9167f04bc822d43230f7564:latest\n",
            "2021/03/29 09:23:36 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 158.482057)\n",
            "2021/03/29 09:23:36 Populating digests for step ID: acb_step_0...\n",
            "2021/03/29 09:23:39 Successfully populated digests for step ID: acb_step_0\n",
            "2021/03/29 09:23:39 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 105.195673)\n",
            "2021/03/29 09:23:39 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 2.418798)\n",
            "2021/03/29 09:23:39 The following dependencies were found:\n",
            "2021/03/29 09:23:39 \n",
            "- image:\n",
            "    registry: mlservice1724bc10.azurecr.io\n",
            "    repository: azureml/azureml_18ce9a15f9167f04bc822d43230f7564\n",
            "    tag: latest\n",
            "    digest: sha256:31d81ed9ba79f8fadbad81b585d1c7b0a3af61ff53b1f66a471c22ace5fa658a\n",
            "  runtime-dependency:\n",
            "    registry: mcr.microsoft.com\n",
            "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
            "    tag: 20210301.v1\n",
            "    digest: sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            "  git: {}\n",
            "- image:\n",
            "    registry: mlservice1724bc10.azurecr.io\n",
            "    repository: azureml/azureml_18ce9a15f9167f04bc822d43230f7564\n",
            "    tag: \"1\"\n",
            "    digest: sha256:31d81ed9ba79f8fadbad81b585d1c7b0a3af61ff53b1f66a471c22ace5fa658a\n",
            "  runtime-dependency:\n",
            "    registry: mcr.microsoft.com\n",
            "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
            "    tag: 20210301.v1\n",
            "    digest: sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            "  git: {}\n",
            "\n",
            "Run ID: cc1t was successful after 4m34s\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_f90b4dcdd70b3541be5ccc8deb10d86c11be4aabbde2eb4bbcb46f95a088dca1_d.txt\n",
            "========================================================================================================================\n",
            "2021-03-29T09:27:53Z Starting output-watcher...\n",
            "2021-03-29T09:27:53Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
            "2021-03-29T09:27:53Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
            "2021-03-29T09:27:53Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
            "2021-03-29T09:27:53Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
            ">>>   \n",
            ">>>   \n",
            "2021-03-29T09:27:54Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
            ">>>   \n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_e9822551ca2eb34193179037c65b7fe1e9589822d1e5c36f40e2dd48b6d823cd_d.txt\n",
            "========================================================================================================================\n",
            "2021-03-29T09:27:53Z Starting output-watcher...\n",
            "2021-03-29T09:27:53Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
            "Login Succeeded\n",
            "Using default tag: latest\n",
            "latest: Pulling from azureml/azureml_18ce9a15f9167f04bc822d43230f7564\n",
            "4007a89234b4: Pulling fs layer\n",
            "5dfa26c6b9c9: Pulling fs layer\n",
            "0ba7bf18aa40: Pulling fs layer\n",
            "4c6ec688ebe3: Pulling fs layer\n",
            "574f361512d6: Pulling fs layer\n",
            "db4d1e2d7079: Pulling fs layer\n",
            "e544ee0f522d: Pulling fs layer\n",
            "c655136086be: Pulling fs layer\n",
            "2ec37f44090c: Pulling fs layer\n",
            "5fba3bd4a2c4: Pulling fs layer\n",
            "7e0ea9d0a1ab: Pulling fs layer\n",
            "da005f826951: Pulling fs layer\n",
            "4c6ec688ebe3: Waiting\n",
            "cc048846b3fc: Pulling fs layer\n",
            "c3d2fcc087eb: Pulling fs layer\n",
            "80e0ed98f058: Pulling fs layer\n",
            "574f361512d6: Waiting\n",
            "35bae1a85389: Pulling fs layer\n",
            "53566d5abdba: Pulling fs layer\n",
            "92f2400e0cfe: Pulling fs layer\n",
            "62f92d7b0b9b: Pulling fs layer\n",
            "86aa9b9da49d: Pulling fs layer\n",
            "e544ee0f522d: Waiting\n",
            "ecac24b717f8: Pulling fs layer\n",
            "c655136086be: Waiting\n",
            "2ec37f44090c: Waiting\n",
            "da005f826951: Waiting\n",
            "5fba3bd4a2c4: Waiting\n",
            "cc048846b3fc: Waiting\n",
            "c3d2fcc087eb: Waiting\n",
            "7e0ea9d0a1ab: Waiting\n",
            "80e0ed98f058: Waiting\n",
            "35bae1a85389: Waiting\n",
            "53566d5abdba: Waiting\n",
            "db4d1e2d7079: Waiting\n",
            "92f2400e0cfe: Waiting\n",
            "62f92d7b0b9b: Waiting\n",
            "86aa9b9da49d: Waiting\n",
            "ecac24b717f8: Waiting\n",
            "0ba7bf18aa40: Download complete\n",
            "5dfa26c6b9c9: Verifying Checksum\n",
            "5dfa26c6b9c9: Download complete\n",
            "4c6ec688ebe3: Verifying Checksum\n",
            "4c6ec688ebe3: Download complete\n",
            "4007a89234b4: Verifying Checksum\n",
            "4007a89234b4: Download complete\n",
            "574f361512d6: Verifying Checksum\n",
            "574f361512d6: Download complete\n",
            "db4d1e2d7079: Verifying Checksum\n",
            "db4d1e2d7079: Download complete\n",
            "e544ee0f522d: Verifying Checksum\n",
            "e544ee0f522d: Download complete\n",
            "c655136086be: Verifying Checksum\n",
            "c655136086be: Download complete\n",
            "7e0ea9d0a1ab: Verifying Checksum\n",
            "7e0ea9d0a1ab: Download complete\n",
            "da005f826951: Verifying Checksum\n",
            "da005f826951: Download complete\n",
            "cc048846b3fc: Verifying Checksum\n",
            "cc048846b3fc: Download complete\n",
            "c3d2fcc087eb: Verifying Checksum\n",
            "c3d2fcc087eb: Download complete\n",
            "2ec37f44090c: Verifying Checksum\n",
            "2ec37f44090c: Download complete\n",
            "5fba3bd4a2c4: Verifying Checksum\n",
            "5fba3bd4a2c4: Download complete\n",
            "80e0ed98f058: Verifying Checksum\n",
            "80e0ed98f058: Download complete\n",
            "35bae1a85389: Verifying Checksum\n",
            "35bae1a85389: Download complete\n",
            "4007a89234b4: Pull complete\n",
            "62f92d7b0b9b: Download complete\n",
            "92f2400e0cfe: Download complete\n",
            "5dfa26c6b9c9: Pull complete\n",
            "86aa9b9da49d: Verifying Checksum\n",
            "86aa9b9da49d: Download complete\n",
            "0ba7bf18aa40: Pull complete\n",
            "4c6ec688ebe3: Pull complete\n",
            "ecac24b717f8: Verifying Checksum\n",
            "53566d5abdba: Verifying Checksum\n",
            "574f361512d6: Pull complete\n",
            "db4d1e2d7079: Pull complete\n",
            "e544ee0f522d: Pull complete\n",
            "c655136086be: Pull complete\n",
            "2ec37f44090c: Pull complete\n",
            "5fba3bd4a2c4: Pull complete\n",
            "7e0ea9d0a1ab: Pull complete\n",
            "da005f826951: Pull complete\n",
            "cc048846b3fc: Pull complete\n",
            "c3d2fcc087eb: Pull complete\n",
            "80e0ed98f058: Pull complete\n",
            "35bae1a85389: Pull complete\n",
            "53566d5abdba: Pull complete\n",
            "92f2400e0cfe: Pull complete\n",
            "62f92d7b0b9b: Pull complete\n",
            "86aa9b9da49d: Pull complete\n",
            "ecac24b717f8: Pull complete\n",
            "Digest: sha256:31d81ed9ba79f8fadbad81b585d1c7b0a3af61ff53b1f66a471c22ace5fa658a\n",
            "Status: Downloaded newer image for mlservice1724bc10.azurecr.io/azureml/azureml_18ce9a15f9167f04bc822d43230f7564:latest\n",
            "mlservice1724bc10.azurecr.io/azureml/azureml_18ce9a15f9167f04bc822d43230f7564:latest\n",
            "2021-03-29T09:28:25Z Check if container 977a5778-f7ff-47d8-bc0b-be5b056d3032 already exist exited with 0, \n",
            "\n",
            "b3457cac65391e4740bae11a7dfd7d72a8f29f16203232983332f8739f0aa0b3\n",
            "2021-03-29T09:28:29Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to true \n",
            "2021-03-29T09:28:29Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-cbb9f0af0192e4d40fce447e17933027-9a2bc1160b05337e-01 -sshRequired=true] \n",
            "2021/03/29 09:28:29 Starting App Insight Logger for task:  containerSetup\n",
            "2021/03/29 09:28:29 Version: 3.0.01535.0005 Branch: 34 Commit: cd98749\n",
            "2021/03/29 09:28:29 Entered ContainerSetupTask - Preparing infiniband\n",
            "2021/03/29 09:28:29 Starting infiniband setup\n",
            "2021/03/29 09:28:29 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
            "2021/03/29 09:28:29 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
            "2021/03/29 09:28:29 Starting setupPasswordLessSSH setup\n",
            "2021/03/29 09:28:29 sshd runtime has already been installed in the container\n",
            "ssh-keygen: /azureml-envs/azureml_695c788487209be000aba32be44fc97b/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
            "ssh-keygen: /azureml-envs/azureml_695c788487209be000aba32be44fc97b/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
            "2021/03/29 09:28:30 All App Insights Logs was send successfully\n",
            "2021/03/29 09:28:30 App Insight Client has already been closed\n",
            "2021/03/29 09:28:30 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "2021-03-29T09:28:30Z Starting docker container succeeded.\n",
            "\n",
            "Streaming azureml-logs/70_driver_log.txt\n",
            "========================================\n",
            "2021/03/29 09:28:42 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
            "2021/03/29 09:28:42 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
            "[2021-03-29T09:28:44.163995] Entering context manager injector.\n",
            "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.25.0', '--scoring_module_name', 'iris_score.py', '--mini_batch_size', '1024', '--error_threshold', '5', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '600', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'iris_outputs.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/977a5778-f7ff-47d8-bc0b-be5b056d3032/mounts/workspaceblobstore/azureml/977a5778-f7ff-47d8-bc0b-be5b056d3032/inferences', '--model_name', 'iris-prs', '--input_ds_0', 'iris_data'])\n",
            "Script type = None\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 136\n",
            "[2021-03-29T09:28:46.058685] Entering Run History Context Manager.\n",
            "[2021-03-29T09:28:46.936924] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/977a5778-f7ff-47d8-bc0b-be5b056d3032/mounts/workspaceblobstore/azureml/977a5778-f7ff-47d8-bc0b-be5b056d3032\n",
            "[2021-03-29T09:28:46.937254] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.25.0', '--scoring_module_name', 'iris_score.py', '--mini_batch_size', '1024', '--error_threshold', '5', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '600', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'iris_outputs.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/977a5778-f7ff-47d8-bc0b-be5b056d3032/mounts/workspaceblobstore/azureml/977a5778-f7ff-47d8-bc0b-be5b056d3032/inferences', '--model_name', 'iris-prs', '--input_ds_0', 'iris_data']\n",
            "[2021-03-29T09:28:46.937318] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.25.0', '--scoring_module_name', 'iris_score.py', '--mini_batch_size', '1024', '--error_threshold', '5', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '600', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'iris_outputs.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/977a5778-f7ff-47d8-bc0b-be5b056d3032/mounts/workspaceblobstore/azureml/977a5778-f7ff-47d8-bc0b-be5b056d3032/inferences', '--model_name', 'iris-prs', '--input_ds_0', 'iris_data']\n",
            "\n",
            "2021/03/29 09:28:47 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_e9822551ca2eb34193179037c65b7fe1e9589822d1e5c36f40e2dd48b6d823cd_d.txt\n",
            "===============================================================================================================\n",
            "[2021-03-29T09:29:53.069408] Entering job release\n",
            "[2021-03-29T09:29:54.070876] job release stage : copy_batchai_cached_logs starting...\n",
            "[2021-03-29T09:29:54.070943] job release stage : copy_batchai_cached_logs completed...\n",
            "\n",
            "StepRun(example-iris) Execution Summary\n",
            "========================================\n",
            "StepRun( example-iris ) Status: Finished\n",
            "{'runId': '977a5778-f7ff-47d8-bc0b-be5b056d3032', 'target': 'ds3cluster', 'status': 'Completed', 'startTimeUtc': '2021-03-29T09:27:47.466527Z', 'endTimeUtc': '2021-03-29T09:30:12.975938Z', 'properties': {'ContentSnapshotId': 'a3dee5e0-02dd-4925-ba54-3ee70ebd7b69', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '4e7b9b06-2ad2-48d3-b044-05cd51e40b13', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '6be526d3', 'azureml.pipelinerunid': '7ee258d4-451c-4c27-88e7-e8c97a71e276', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [{'dataset': {'id': '05260fe3-2611-4845-a56c-db0528654842'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'iris_data', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.25.0', '--scoring_module_name', 'iris_score.py', '--mini_batch_size', '1024', '--error_threshold', '5', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '600', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'iris_outputs.txt', '--output', '$AZUREML_DATAREFERENCE_inferences', '--model_name', 'iris-prs', '--input_ds_0', 'iris_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'ds3cluster', 'dataReferences': {'inferences': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/977a5778-f7ff-47d8-bc0b-be5b056d3032/inferences', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'iris_data': {'dataLocation': {'dataset': {'id': '05260fe3-2611-4845-a56c-db0528654842', 'name': None, 'version': None}, 'dataPath': None}, 'mechanism': 'Direct', 'environmentVariableName': 'iris_data', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'predict_environment', 'version': 'Autosave_2021-03-29T09:19:00Z_68db0d11', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['scikit-learn==0.20.3', 'azureml-core~=1.25.0', 'azureml-dataset-runtime[pandas,fuse]~=1.25.0']}], 'name': 'azureml_695c788487209be000aba32be44fc97b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': False}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=cG%2Bn5D8sM9N4%2Fe%2FJvXV9n9lZJ9z2u7ub7Aw%2B9kwJj84%3D&st=2021-03-29T09%3A19%3A54Z&se=2021-03-29T17%3A29%3A54Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_e9822551ca2eb34193179037c65b7fe1e9589822d1e5c36f40e2dd48b6d823cd_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/azureml-logs/55_azureml-execution-tvmps_e9822551ca2eb34193179037c65b7fe1e9589822d1e5c36f40e2dd48b6d823cd_d.txt?sv=2019-02-02&sr=b&sig=GRXJsr1kII8HcVGoVQwDu5t6PzyMDeXN2q9%2BLSoFdrc%3D&st=2021-03-29T09%3A19%3A54Z&se=2021-03-29T17%3A29%3A54Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_f90b4dcdd70b3541be5ccc8deb10d86c11be4aabbde2eb4bbcb46f95a088dca1_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/azureml-logs/55_azureml-execution-tvmps_f90b4dcdd70b3541be5ccc8deb10d86c11be4aabbde2eb4bbcb46f95a088dca1_d.txt?sv=2019-02-02&sr=b&sig=fPs688wPnueT45GTIfcy11qTK8XVjlm0AT6GLo0o6Mg%3D&st=2021-03-29T09%3A19%3A54Z&se=2021-03-29T17%3A29%3A54Z&sp=r', 'azureml-logs/65_job_prep-tvmps_e9822551ca2eb34193179037c65b7fe1e9589822d1e5c36f40e2dd48b6d823cd_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/azureml-logs/65_job_prep-tvmps_e9822551ca2eb34193179037c65b7fe1e9589822d1e5c36f40e2dd48b6d823cd_d.txt?sv=2019-02-02&sr=b&sig=OdqJjd6lIlbg4G1st9HOwPGxmAQxreXC%2FE%2FzysTb4sk%3D&st=2021-03-29T09%3A19%3A54Z&se=2021-03-29T17%3A29%3A54Z&sp=r', 'azureml-logs/65_job_prep-tvmps_f90b4dcdd70b3541be5ccc8deb10d86c11be4aabbde2eb4bbcb46f95a088dca1_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/azureml-logs/65_job_prep-tvmps_f90b4dcdd70b3541be5ccc8deb10d86c11be4aabbde2eb4bbcb46f95a088dca1_d.txt?sv=2019-02-02&sr=b&sig=oAGziLjbQRChEwLtlvI%2BQ0lz4TTAyrERYCLfMlbalAo%3D&st=2021-03-29T09%3A19%3A54Z&se=2021-03-29T17%3A29%3A54Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=KjiBFB9f2fXtJMAR0YeLcTKnjmv6J3EN0bHY8SPpUYs%3D&st=2021-03-29T09%3A19%3A54Z&se=2021-03-29T17%3A29%3A54Z&sp=r', 'azureml-logs/75_job_post-tvmps_e9822551ca2eb34193179037c65b7fe1e9589822d1e5c36f40e2dd48b6d823cd_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/azureml-logs/75_job_post-tvmps_e9822551ca2eb34193179037c65b7fe1e9589822d1e5c36f40e2dd48b6d823cd_d.txt?sv=2019-02-02&sr=b&sig=HCuNcnlFl8219bKQtuEd%2BkWUwStoTby%2FOK2RmJTJVgU%3D&st=2021-03-29T09%3A19%3A54Z&se=2021-03-29T17%3A29%3A54Z&sp=r', 'azureml-logs/75_job_post-tvmps_f90b4dcdd70b3541be5ccc8deb10d86c11be4aabbde2eb4bbcb46f95a088dca1_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/azureml-logs/75_job_post-tvmps_f90b4dcdd70b3541be5ccc8deb10d86c11be4aabbde2eb4bbcb46f95a088dca1_d.txt?sv=2019-02-02&sr=b&sig=LTwn0TLGxOaYtBF4dXT8OuFPk9lQ0ZcXZSIA%2BAzz%2FOA%3D&st=2021-03-29T09%3A19%3A54Z&se=2021-03-29T17%3A29%3A54Z&sp=r', 'azureml-logs/process_info.json': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=QjGyh51qN0ZqRZzE4kuuu8RThkaWxkKm%2BlkHpymCwkg%3D&st=2021-03-29T09%3A19%3A54Z&se=2021-03-29T17%3A29%3A54Z&sp=r', 'azureml-logs/process_status.json': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=Afn1H5b2dnUNVNZAucn67reroo%2FUKspEmNQjsfcFRSg%3D&st=2021-03-29T09%3A19%3A54Z&se=2021-03-29T17%3A29%3A54Z&sp=r', 'logs/azureml/121_azureml.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/logs/azureml/121_azureml.log?sv=2019-02-02&sr=b&sig=DdCZHYhvHlYaKNoj%2FipcPVVUt5PJ5FxaJFY1LopAOew%3D&st=2021-03-29T09%3A19%3A58Z&se=2021-03-29T17%3A29%3A58Z&sp=r', 'logs/azureml/136_azureml.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/logs/azureml/136_azureml.log?sv=2019-02-02&sr=b&sig=Zt%2FwFWdu2gxgt49DZBn75dMiIgWR%2FJXx6WS%2Fm1nFyEk%3D&st=2021-03-29T09%3A19%3A58Z&se=2021-03-29T17%3A29%3A58Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=ls56BCOD8grWWzib2L67AGr6NVIxJUSJvzCMn2brI3g%3D&st=2021-03-29T09%3A19%3A58Z&se=2021-03-29T17%3A29%3A58Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=%2FuJMLYsrykjM7wPDYtldVqvhzBvvMVF6n%2Br%2BL80mdAQ%3D&st=2021-03-29T09%3A19%3A58Z&se=2021-03-29T17%3A29%3A58Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=8JshyKUN7DNxpNSaANGNlzGY9aapGmm%2FTw8RyNUYbgw%3D&st=2021-03-29T09%3A19%3A58Z&se=2021-03-29T17%3A29%3A58Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=pJ5IJZwVk743ltlSvzU3iiyLM3wncktF%2FVG6ZxCs3lw%3D&st=2021-03-29T09%3A19%3A58Z&se=2021-03-29T17%3A29%3A58Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=f9gtDgLtAhY5mIw2HR%2FBy99F2PwpGQg8BbSPTTz0KG4%3D&st=2021-03-29T09%3A19%3A58Z&se=2021-03-29T17%3A29%3A58Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=FeXQmcADG5ozq9phXjFwSlkozb0NbHQnFyU%2F8CioJCA%3D&st=2021-03-29T09%3A19%3A58Z&se=2021-03-29T17%3A29%3A58Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.977a5778-f7ff-47d8-bc0b-be5b056d3032/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=OPwiKs01QOdQohXkuUhxHE1mqVPkvYSRkyAwjxchZLM%3D&st=2021-03-29T09%3A19%3A58Z&se=2021-03-29T17%3A29%3A58Z&sp=r'}, 'submittedBy': 'Anil Dwarakanath'}\n",
            "\n",
            "\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "{'runId': '7ee258d4-451c-4c27-88e7-e8c97a71e276', 'status': 'Completed', 'startTimeUtc': '2021-03-29T09:18:23.870738Z', 'endTimeUtc': '2021-03-29T09:30:14.757443Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.7ee258d4-451c-4c27-88e7-e8c97a71e276/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=ql6ppg8mhuur0RAxovzHSEtK58iqS8TtskCvd0QJ1MU%3D&st=2021-03-29T09%3A08%3A42Z&se=2021-03-29T17%3A18%3A42Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.7ee258d4-451c-4c27-88e7-e8c97a71e276/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=X1Wzg4C4hSbvjJZDG15by%2BcX3mxaGry3dkqASK%2BAVVo%3D&st=2021-03-29T09%3A08%3A42Z&se=2021-03-29T17%3A18%3A42Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.7ee258d4-451c-4c27-88e7-e8c97a71e276/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=qKVy0tNirrNfj3quWvZTdlLK9CZQxvjf4fj2C5hFq%2Bs%3D&st=2021-03-29T09%3A08%3A42Z&se=2021-03-29T17%3A18%3A42Z&sp=r'}, 'submittedBy': 'Anil Dwarakanath'}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Finished'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "## Wait the run for completion and show output log to console\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View Results\n",
        "In the iris_score.py file above you can see that the Result with the prediction of the iris variety gets returned and then appended to the original input of the row from the csv file. These results are written to the DataStore specified in the PipelineData object as the output data, which in this case is called *inferences*. This contains the outputs from  all of the worker nodes used in the compute cluster. You can download this data to view the results ... below just filters to a random 20 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction has  74  rows\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sepal.length  sepal.width  petal.length  petal.width          variety\n",
              "47           5.3          3.7           1.5          0.2      Iris-setosa\n",
              "15           4.8          3.0           1.4          0.1      Iris-setosa\n",
              "4            4.4          3.2           1.3          0.2      Iris-setosa\n",
              "55           5.8          4.0           1.2          0.2      Iris-setosa\n",
              "64           5.4          3.4           1.7          0.2      Iris-setosa\n",
              "65           6.3          2.5           4.9          1.5  Iris-versicolor\n",
              "66           6.3          3.3           4.7          1.6   Iris-virginica\n",
              "18           5.1          3.7           1.5          0.4      Iris-setosa\n",
              "35           4.7          3.2           1.3          0.2      Iris-setosa\n",
              "45           6.5          2.8           4.6          1.5   Iris-virginica\n",
              "51           5.4          3.4           1.5          0.4      Iris-setosa\n",
              "14           5.2          3.5           1.5          0.2      Iris-setosa\n",
              "19           4.6          3.2           1.4          0.2      Iris-setosa\n",
              "2            5.4          3.9           1.3          0.4      Iris-setosa\n",
              "73           6.1          2.8           4.7          1.2  Iris-versicolor\n",
              "63           4.6          3.1           1.5          0.2      Iris-setosa\n",
              "8            5.1          3.4           1.5          0.2      Iris-setosa\n",
              "72           6.2          2.2           4.5          1.5  Iris-versicolor\n",
              "49           5.4          3.7           1.5          0.2      Iris-setosa\n",
              "70           5.0          3.3           1.4          0.2      Iris-setosa"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal.length</th>\n      <th>sepal.width</th>\n      <th>petal.length</th>\n      <th>petal.width</th>\n      <th>variety</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>47</th>\n      <td>5.3</td>\n      <td>3.7</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>4.8</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.1</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.4</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>5.8</td>\n      <td>4.0</td>\n      <td>1.2</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>5.4</td>\n      <td>3.4</td>\n      <td>1.7</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>4.9</td>\n      <td>1.5</td>\n      <td>Iris-versicolor</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>6.3</td>\n      <td>3.3</td>\n      <td>4.7</td>\n      <td>1.6</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>5.1</td>\n      <td>3.7</td>\n      <td>1.5</td>\n      <td>0.4</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>6.5</td>\n      <td>2.8</td>\n      <td>4.6</td>\n      <td>1.5</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>5.4</td>\n      <td>3.4</td>\n      <td>1.5</td>\n      <td>0.4</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>5.2</td>\n      <td>3.5</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>4.6</td>\n      <td>3.2</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.4</td>\n      <td>3.9</td>\n      <td>1.3</td>\n      <td>0.4</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>6.1</td>\n      <td>2.8</td>\n      <td>4.7</td>\n      <td>1.2</td>\n      <td>Iris-versicolor</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>5.1</td>\n      <td>3.4</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>6.2</td>\n      <td>2.2</td>\n      <td>4.5</td>\n      <td>1.5</td>\n      <td>Iris-versicolor</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>5.4</td>\n      <td>3.7</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>5.0</td>\n      <td>3.3</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tempfile\n",
        "\n",
        "prediction_run = pipeline_run.find_step_run(distributed_csv_iris_step.name)[0]\n",
        "prediction_output = prediction_run.get_output_data(output_folder.name)\n",
        "\n",
        "target_dir = tempfile.mkdtemp()\n",
        "prediction_output.download(local_path=target_dir)\n",
        "result_file = os.path.join(target_dir, prediction_output.path_on_datastore, parallel_run_config.append_row_file_name)\n",
        "\n",
        "# cleanup output format\n",
        "df = pd.read_csv(result_file, delimiter=\" \", header=None)\n",
        "df.columns = [\"sepal.length\", \"sepal.width\", \"petal.length\", \"petal.width\", \"variety\"]\n",
        "print(\"Prediction has \", df.shape[0], \" rows\")\n",
        "\n",
        "random_subset = df.sample(n=20)\n",
        "random_subset.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup compute resources\n",
        "For re-occurring jobs, it may be wise to keep compute the compute resources and allow compute nodes to scale down to 0. However, since this is just a single run job, we are free to release the allocated compute resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# uncomment below and run if compute resources are no longer needed \n",
        "# compute_target.delete()"
      ]
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "joringer"
      },
      {
        "name": "asraniwa"
      },
      {
        "name": "pansav"
      },
      {
        "name": "tracych"
      }
    ],
    "category": "Other notebooks",
    "compute": [
      "AML Compute"
    ],
    "datasets": [
      "IRIS"
    ],
    "deployment": [
      "None"
    ],
    "exclude_from_index": false,
    "framework": [
      "None"
    ],
    "friendly_name": "IRIS data inferencing using ParallelRunStep",
    "index_order": 1,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.10 64-bit ('aml': conda)",
      "metadata": {
        "interpreter": {
          "hash": "a5d4df4a22655ddcd3995113ae21abdf5e3f153b58eb8770b042525e3ea05670"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10-final"
    },
    "tags": [
      "Batch Inferencing",
      "Pipeline"
    ],
    "task": "Recognize flower type"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}