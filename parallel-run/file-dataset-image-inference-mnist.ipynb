{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.25.0\n"
          ]
        }
      ],
      "source": [
        "# Check core SDK version number\n",
        "import azureml.core\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Falling back to use azure cli login credentials.\n",
            "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
            "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n",
            "Workspace name: ml-service\n",
            "Azure region: westus2\n",
            "Subscription id: 3e0e14b3-7e28-4da7-97de-0f5cb324f030\n",
            "Resource group: ml\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create or Attach existing compute resource\n",
        "By using Azure Machine Learning Compute, a managed service, data scientists can train machine learning models on clusters of Azure virtual machines. Examples include VMs with GPU support. In this tutorial, you create Azure Machine Learning Compute as your training environment. The code below creates the compute clusters for you if they don't already exist in your workspace.\n",
        "\n",
        "**Creation of compute takes approximately 5 minutes. If the AmlCompute with that name is already in your workspace the code will skip the creation process.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found compute target. just use it. ds3cluster\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from azureml.core.compute import AmlCompute, ComputeTarget\n",
        "\n",
        "# choose a name for your cluster\n",
        "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"ds3cluster\")\n",
        "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
        "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 2)\n",
        "\n",
        "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
        "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_DS3_V2\")\n",
        "\n",
        "\n",
        "if compute_name in ws.compute_targets:\n",
        "    compute_target = ws.compute_targets[compute_name]\n",
        "    if compute_target and type(compute_target) is AmlCompute:\n",
        "        print('found compute target. just use it. ' + compute_name)\n",
        "else:\n",
        "    print('creating a new compute target...')\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
        "                                                                min_nodes = compute_min_nodes, \n",
        "                                                                max_nodes = compute_max_nodes)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
        "    \n",
        "    # can poll for a minimum number of nodes and for a specific timeout. \n",
        "    # if no min node count is provided it will use the scale settings for the cluster\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "    \n",
        "     # For a more detailed view of current AmlCompute status, use get_status()\n",
        "    print(compute_target.get_status().serialize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a datastore containing sample images\n",
        "The input dataset used for this notebook differs from a standard MNIST dataset in that it has been converted to PNG images to demonstrate use of files as inputs to Batch Inference. A sample of PNG-converted images of the MNIST dataset were take from [this repository](https://github.com/myleott/mnist_png).\n",
        "\n",
        "We have created a public blob container `sampledata` on an account named `pipelinedata`, containing these images from the MNIST dataset. In the next step, we create a datastore with the name `images_datastore`, which points to this blob container. In the call to `register_azure_blob_container` below, setting the `overwrite` flag to `True` overwrites any datastore that was created previously with that name. \n",
        "\n",
        "This step can be changed to point to your blob container by providing your own `datastore_name`, `container_name`, and `account_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.datastore import Datastore\n",
        "\n",
        "account_name = \"pipelinedata\"\n",
        "datastore_name = \"mnist_datastore\"\n",
        "container_name = \"sampledata\"\n",
        "\n",
        "mnist_data = Datastore.register_azure_blob_container(ws, \n",
        "                      datastore_name=datastore_name, \n",
        "                      container_name=container_name, \n",
        "                      account_name=account_name,\n",
        "                      overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let's specify the default datastore for the outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def_data_store = ws.get_default_datastore()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a FileDataset\n",
        "A [FileDataset](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.filedataset?view=azure-ml-py) references single or multiple files in your datastores or public urls. The files can be of any format. FileDataset provides you with the ability to download or mount the files to your compute. By creating a dataset, you create a reference to the data source location. If you applied any subsetting transformations to the dataset, they will be stored in the dataset as well. The data remains in its existing location, so no extra storage cost is incurred.\n",
        "\n",
        "You can use dataset objects as inputs. Register the datasets to the workspace if you want to reuse them later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "mnist_ds_name = 'mnist_sample_data'\n",
        "\n",
        "path_on_datastore = mnist_data.path('mnist')\n",
        "input_mnist_ds = Dataset.File.from_files(path=path_on_datastore, validate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The input dataset can be specified as a pipeline parameter, so that you can pass in new data when rerun the PRS pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.data.dataset_consumption_config import DatasetConsumptionConfig\n",
        "from azureml.pipeline.core import PipelineParameter\n",
        "\n",
        "pipeline_param = PipelineParameter(name=\"mnist_param\", default_value=input_mnist_ds)\n",
        "input_mnist_ds_consumption = DatasetConsumptionConfig(\"minist_param_config\", pipeline_param).as_mount()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Intermediate/Output Data\n",
        "Intermediate data (or output of a Step) is represented by [PipelineData](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipelinedata?view=azure-ml-py) object. PipelineData can be produced by one step and consumed in another step by providing the PipelineData object as an output of one step and the input of one or more steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import Pipeline, PipelineData\n",
        "\n",
        "output_dir = PipelineData(name=\"inferences\", datastore=def_data_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download the Model\n",
        "\n",
        "Download and extract the model from https://pipelinedata.blob.core.windows.net/mnist-model/mnist-tf.tar.gz to \"models\" directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "# create directory for model\n",
        "model_dir = 'models'\n",
        "if not os.path.isdir(model_dir):\n",
        "    os.mkdir(model_dir)\n",
        "\n",
        "url=\"https://pipelinedata.blob.core.windows.net/mnist-model/mnist-tf.tar.gz\"\n",
        "response = urllib.request.urlretrieve(url, \"model.tar.gz\")\n",
        "tar = tarfile.open(\"model.tar.gz\", \"r:gz\")\n",
        "tar.extractall(model_dir)\n",
        "\n",
        "os.listdir(model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Register the model with Workspace\n",
        "A registered model is a logical container for one or more files that make up your model. For example, if you have a model that's stored in multiple files, you can register them as a single model in the workspace. After you register the files, you can then download or deploy the registered model and receive all the files that you registered.\n",
        "\n",
        "Using tags, you can track useful information such as the name and version of the machine learning library used to train the model. Note that tags must be alphanumeric. Learn more about registering models [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-deploy-and-where#registermodel) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.model import Model\n",
        "\n",
        "# register downloaded model \n",
        "model = Model.register(model_path=\"models/\",\n",
        "                       model_name=\"mnist-prs\", # this is the name the model is registered as\n",
        "                       tags={'pretrained': \"mnist\"},\n",
        "                       description=\"Mnist trained tensorflow model\",\n",
        "                       workspace=ws)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using your model to make batch predictions\n",
        "To use the model to make batch predictions, you need an **entry script** and a list of **dependencies**:\n",
        "\n",
        "#### An entry script\n",
        "This script accepts requests, scores the requests by using the model, and returns the results.\n",
        "- __init()__ - Typically this function loads the model into a global object. This function is run only once at the start of batch processing per worker node/process. Init method can make use of following environment variables (ParallelRunStep input):\n",
        "    1.\tAZUREML_BI_OUTPUT_PATH â€“ output folder path\n",
        "- __run(mini_batch)__ - The method to be parallelized. Each invocation will have one minibatch.<BR>\n",
        "__mini_batch__: Batch inference will invoke run method and pass either a list or Pandas DataFrame as an argument to the method. Each entry in min_batch will be - a filepath if input is a FileDataset, a Pandas DataFrame if input is a TabularDataset.<BR>\n",
        "__run__ method response: run() method should return a Pandas DataFrame or an array. For append_row output_action, these returned elements are appended into the common output file. For summary_only, the contents of the elements are ignored. For all output actions, each returned output element indicates one successful inference of input element in the input mini-batch.\n",
        "    User should make sure that enough data is included in inference result to map input to inference. Inference output will be written in output file and not guaranteed to be in order, user should use some key in the output to map it to input.\n",
        "    \n",
        "\n",
        "#### Dependencies\n",
        "Helper scripts or Python/Conda packages required to run the entry script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scripts_folder = \"Code\"\n",
        "script_file = \"digit_identification.py\"\n",
        "\n",
        "# peek at contents\n",
        "with open(os.path.join(scripts_folder, script_file)) as inference_file:\n",
        "    print(inference_file.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build and run the batch inference pipeline\n",
        "The data, models, and compute resource are now available. Let's put all these together in a pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Specify the environment to run the script\n",
        "Specify the conda dependencies for your script. This will allow us to install pip packages as well as configure the inference environment.\n",
        "* Always include **azureml-core** and **azureml-dataset-runtime\\[fuse\\]** in the pip package list to make ParallelRunStep run properly.\n",
        "\n",
        "If you're using custom image (`batch_env.python.user_managed_dependencies = True`), you need to install the package to your image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.runconfig import CondaDependencies, DEFAULT_CPU_IMAGE\n",
        "\n",
        "batch_conda_deps = CondaDependencies.create(pip_packages=[\"tensorflow==1.15.2\", \"pillow\", \n",
        "                                                          \"azureml-core\", \"azureml-dataset-runtime[fuse]\"])\n",
        "batch_env = Environment(name=\"batch_environment\")\n",
        "batch_env.python.conda_dependencies = batch_conda_deps\n",
        "batch_env.docker.enabled = True\n",
        "batch_env.docker.base_image = DEFAULT_CPU_IMAGE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Create the configuration to wrap the inference script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.steps import ParallelRunStep, ParallelRunConfig\n",
        "\n",
        "parallel_run_config = ParallelRunConfig(\n",
        "    source_directory=scripts_folder,\n",
        "    entry_script=script_file,\n",
        "    mini_batch_size=PipelineParameter(name=\"batch_size_param\", default_value=\"5\"),\n",
        "    error_threshold=10,\n",
        "    output_action=\"append_row\",\n",
        "    append_row_file_name=\"mnist_outputs.txt\",\n",
        "    environment=batch_env,\n",
        "    compute_target=compute_target,\n",
        "    process_count_per_node=PipelineParameter(name=\"process_count_param\", default_value=2),\n",
        "    node_count=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create the pipeline step\n",
        "Create the pipeline step using the script, environment configuration, and parameters. Specify the compute target you already attached to your workspace as the target of execution of the script. We will use ParallelRunStep to create the pipeline step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
          ]
        }
      ],
      "source": [
        "parallelrun_step = ParallelRunStep(\n",
        "    name=\"predict-digits-mnist\",\n",
        "    parallel_run_config=parallel_run_config,\n",
        "    inputs=[ input_mnist_ds_consumption ],\n",
        "    output=output_dir,\n",
        "    allow_reuse=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the pipeline\n",
        "At this point you can run the pipeline and examine the output it produced. The Experiment object is used to track the run of the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created step predict-digits-mnist [09691726][7dd94648-c082-4d96-abb3-6fc2463f963f], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun 1d217fb3-d9cd-4be9-a772-7490b7d75795\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/1d217fb3-d9cd-4be9-a772-7490b7d75795?wsid=/subscriptions/3e0e14b3-7e28-4da7-97de-0f5cb324f030/resourcegroups/ml/workspaces/ml-service&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Experiment\n",
        "\n",
        "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
        "experiment = Experiment(ws, 'digit_identification')\n",
        "pipeline_run = experiment.submit(pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Monitor the run\n",
        "\n",
        "The pipeline run status could be checked in Azure Machine Learning portal (https://ml.azure.com). The link to the pipeline run could be retrieved by inspecting the `pipeline_run` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Run(Experiment: digit_identification,\n",
              "Id: 1d217fb3-d9cd-4be9-a772-7490b7d75795,\n",
              "Type: azureml.PipelineRun,\n",
              "Status: Preparing)"
            ],
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>digit_identification</td><td>1d217fb3-d9cd-4be9-a772-7490b7d75795</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/1d217fb3-d9cd-4be9-a772-7490b7d75795?wsid=/subscriptions/3e0e14b3-7e28-4da7-97de-0f5cb324f030/resourcegroups/ml/workspaces/ml-service&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# This will output information of the pipeline run, including the link to the details page of portal.\n",
        "pipeline_run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: View detailed logs (streaming) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineRunId: 1d217fb3-d9cd-4be9-a772-7490b7d75795\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/1d217fb3-d9cd-4be9-a772-7490b7d75795?wsid=/subscriptions/3e0e14b3-7e28-4da7-97de-0f5cb324f030/resourcegroups/ml/workspaces/ml-service&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: 559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e?wsid=/subscriptions/3e0e14b3-7e28-4da7-97de-0f5cb324f030/resourcegroups/ml/workspaces/ml-service&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "StepRun( predict-digits-mnist ) Status: NotStarted\n",
            "StepRun( predict-digits-mnist ) Status: Queued\n",
            "\n",
            "Streaming azureml-logs/20_image_build_log.txt\n",
            "=============================================\n",
            "2021/03/29 08:29:47 Downloading source code...\n",
            "2021/03/29 08:29:48 Finished downloading source code\n",
            "2021/03/29 08:29:48 Creating Docker network: acb_default_network, driver: 'bridge'\n",
            "2021/03/29 08:29:49 Successfully set up Docker network: acb_default_network\n",
            "2021/03/29 08:29:49 Setting up Docker configuration...\n",
            "2021/03/29 08:29:50 Successfully set up Docker configuration\n",
            "2021/03/29 08:29:50 Logging in to registry: mlservice1724bc10.azurecr.io\n",
            "2021/03/29 08:29:51 Successfully logged into mlservice1724bc10.azurecr.io\n",
            "2021/03/29 08:29:51 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/03/29 08:29:51 Scanning for dependencies...\n",
            "2021/03/29 08:29:51 Successfully scanned dependencies\n",
            "2021/03/29 08:29:51 Launching container with name: acb_step_0\n",
            "Sending build context to Docker daemon  66.56kB\n",
            "\n",
            "Step 1/18 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1@sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            "sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df: Pulling from azureml/intelmpi2018.3-ubuntu16.04\n",
            "Digest: sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            "Status: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1@sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            " ---> c942df5ba5d0\n",
            "Step 2/18 : USER root\n",
            " ---> Running in ca870955d589\n",
            "Removing intermediate container ca870955d589\n",
            " ---> 5106ee02709c\n",
            "Step 3/18 : RUN mkdir -p $HOME/.cache\n",
            " ---> Running in bcf32f5b7dd1\n",
            "Removing intermediate container bcf32f5b7dd1\n",
            " ---> cda25bc873fa\n",
            "Step 4/18 : WORKDIR /\n",
            " ---> Running in 21d1405b3995\n",
            "Removing intermediate container 21d1405b3995\n",
            " ---> d15f34051b40\n",
            "Step 5/18 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
            " ---> e9e6c5b90f67\n",
            "Step 6/18 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
            " ---> Running in 1bd5582e1352\n",
            "Removing intermediate container 1bd5582e1352\n",
            " ---> ea94af323bd1\n",
            "Step 7/18 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
            " ---> 8e42ca0ad589\n",
            "Step 8/18 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_e724c42fa12ee833d560f6a0b7166664 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
            " ---> Running in c19a0785667c\n",
            "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
            "StepRun( predict-digits-mnist ) Status: Running\n",
            "Collecting package metadata (repodata.json): ...working... \n",
            "done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "wheel-0.35.1         | 36 KB     |            |   0% \n",
            "wheel-0.35.1         | 36 KB     | ####4      |  44% \n",
            "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
            "\n",
            "python-3.6.2         | 27.0 MB   |            |   0% \n",
            "python-3.6.2         | 27.0 MB   | #          |  10% \n",
            "python-3.6.2         | 27.0 MB   | ###6       |  36% \n",
            "python-3.6.2         | 27.0 MB   | #######    |  71% \n",
            "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
            "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
            "\n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
            "\n",
            "ca-certificates-2020 | 128 KB    |            |   0% \n",
            "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
            "\n",
            "setuptools-50.3.0    | 891 KB    |            |   0% \n",
            "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
            "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
            "\n",
            "pip-20.2.4           | 2.0 MB    |            |   0% \n",
            "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
            "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
            "\n",
            "zlib-1.2.11          | 120 KB    |            |   0% \n",
            "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
            "\n",
            "libedit-3.1          | 171 KB    |            |   0% \n",
            "libedit-3.1          | 171 KB    | ########## | 100% \n",
            "\n",
            "ncurses-6.0          | 907 KB    |            |   0% \n",
            "ncurses-6.0          | 907 KB    | ########## | 100% \n",
            "ncurses-6.0          | 907 KB    | ########## | 100% \n",
            "\n",
            "libffi-3.2.1         | 52 KB     |            |   0% \n",
            "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
            "\n",
            "xz-5.2.5             | 438 KB    |            |   0% \n",
            "xz-5.2.5             | 438 KB    | ########## | 100% \n",
            "xz-5.2.5             | 438 KB    | ########## | 100% \n",
            "\n",
            "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
            "libgcc-ng-9.1.0      | 8.1 MB    | #######1   |  72% \n",
            "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
            "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
            "\n",
            "readline-7.0         | 387 KB    |            |   0% \n",
            "readline-7.0         | 387 KB    | ########## | 100% \n",
            "readline-7.0         | 387 KB    | ########## | 100% \n",
            "\n",
            "tk-8.6.10            | 3.2 MB    |            |   0% \n",
            "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
            "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
            "\n",
            "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
            "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
            "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
            "\n",
            "certifi-2020.6.20    | 160 KB    |            |   0% \n",
            "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
            "\n",
            "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
            "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
            "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Installing pip dependencies: ...working... \n",
            "Ran pip subprocess with arguments:\n",
            "['/azureml-envs/azureml_e724c42fa12ee833d560f6a0b7166664/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.i16u7vlj.requirements.txt']\n",
            "Pip subprocess output:\n",
            "Collecting tensorflow==1.15.2\n",
            "  Downloading tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "Collecting pillow\n",
            "  Downloading Pillow-8.1.2-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
            "Collecting azureml-core~=1.25.0\n",
            "  Downloading azureml_core-1.25.0-py3-none-any.whl (2.2 MB)\n",
            "Collecting azureml-dataset-runtime[fuse]~=1.25.0\n",
            "  Downloading azureml_dataset_runtime-1.25.0-py3-none-any.whl (3.4 kB)\n",
            "Collecting wrapt>=1.11.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "Collecting keras-preprocessing>=1.0.5\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Collecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Collecting grpcio>=1.8.6\n",
            "  Downloading grpcio-1.36.1-cp36-cp36m-manylinux2014_x86_64.whl (4.1 MB)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /azureml-envs/azureml_e724c42fa12ee833d560f6a0b7166664/lib/python3.6/site-packages (from tensorflow==1.15.2->-r /azureml-environment-setup/condaenv.i16u7vlj.requirements.txt (line 1)) (0.35.1)\n",
            "Collecting six>=1.10.0\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting astor>=0.6.0\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting absl-py>=0.7.0\n",
            "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
            "Collecting google-pasta>=0.1.6\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Collecting numpy<2.0,>=1.16.0\n",
            "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "Collecting termcolor>=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "Collecting protobuf>=3.6.1\n",
            "  Downloading protobuf-3.15.6-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
            "Collecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
            "Collecting urllib3>=1.23\n",
            "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
            "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
            "Collecting pyopenssl<21.0.0\n",
            "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
            "Collecting backports.tempfile\n",
            "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting pathspec\n",
            "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
            "Collecting ndg-httpsclient\n",
            "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
            "Collecting docker\n",
            "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
            "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
            "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
            "Collecting adal>=1.2.0\n",
            "  Downloading adal-1.2.6-py2.py3-none-any.whl (55 kB)\n",
            "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n",
            "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "Collecting PyJWT<3.0.0\n",
            "  Downloading PyJWT-2.0.1-py3-none-any.whl (15 kB)\n",
            "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
            "  Downloading azure_mgmt_resource-12.1.0-py2.py3-none-any.whl (1.1 MB)\n",
            "Collecting ruamel.yaml>=0.15.35\n",
            "  Downloading ruamel.yaml-0.17.0-py2.py3-none-any.whl (101 kB)\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting jmespath\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting azure-common>=1.1.12\n",
            "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
            "Collecting requests<3.0.0,>=2.19.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "Collecting python-dateutil>=2.7.3\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "Collecting SecretStorage\n",
            "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
            "Collecting contextlib2\n",
            "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting msrest>=0.5.1\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
            "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
            "Collecting msrestazure>=0.4.33\n",
            "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
            "Collecting pytz\n",
            "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
            "Collecting azure-mgmt-containerregistry>=2.0.0\n",
            "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
            "Collecting azureml-dataprep<2.12.0a,>=2.11.0a\n",
            "  Downloading azureml_dataprep-2.11.2-py3-none-any.whl (39.4 MB)\n",
            "Collecting pyarrow<2.0.0,>=0.17.0\n",
            "  Downloading pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3 MB)\n",
            "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
            "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
            "Collecting h5py\n",
            "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /azureml-envs/azureml_e724c42fa12ee833d560f6a0b7166664/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2->-r /azureml-environment-setup/condaenv.i16u7vlj.requirements.txt (line 1)) (50.3.0.post20201006)\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
            "Collecting backports.weakref\n",
            "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
            "Collecting pyasn1>=0.1.1\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-0.58.0-py2.py3-none-any.whl (61 kB)\n",
            "Collecting cffi>=1.12\n",
            "  Downloading cffi-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
            "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n",
            "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
            "Collecting importlib-metadata; python_version < \"3.8\"\n",
            "  Downloading importlib_metadata-3.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting idna<3,>=2.5\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "Collecting chardet<5,>=3.0.2\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_e724c42fa12ee833d560f6a0b7166664/lib/python3.6/site-packages (from requests<3.0.0,>=2.19.1->azureml-core~=1.25.0->-r /azureml-environment-setup/condaenv.i16u7vlj.requirements.txt (line 3)) (2020.6.20)\n",
            "Collecting jeepney>=0.6\n",
            "  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "Collecting requests-oauthlib>=0.5.0\n",
            "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting azureml-dataprep-native<31.0.0,>=30.0.0\n",
            "  Downloading azureml_dataprep_native-30.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
            "Collecting azure-identity<1.5.0,>=1.2.0\n",
            "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
            "Collecting cloudpickle<2.0.0,>=1.1.0\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting azureml-dataprep-rslex<1.10.0a,>=1.9.0dev0\n",
            "  Downloading azureml_dataprep_rslex-1.9.1-cp36-cp36m-manylinux2010_x86_64.whl (9.0 MB)\n",
            "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
            "  Downloading dotnetcore2-2.1.20-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
            "Collecting cached-property; python_version < \"3.8\"\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting pycparser\n",
            "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
            "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
            "Collecting azure-core<2.0.0,>=1.0.0\n",
            "  Downloading azure_core-1.12.0-py2.py3-none-any.whl (130 kB)\n",
            "Collecting msal<2.0.0,>=1.3.0\n",
            "  Downloading msal-1.10.0-py2.py3-none-any.whl (60 kB)\n",
            "Collecting msal-extensions~=0.2.2\n",
            "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
            "Collecting distro>=1.2.0\n",
            "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting portalocker~=1.0; platform_system != \"Windows\"\n",
            "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: wrapt, gast, termcolor, fusepy\n",
            "  Building wheel for wrapt (setup.py): started\n",
            "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=66283 sha256=9a251a0bf5d04c8470e58b138accfecdfba98675ddcb7254e414ae2735f8d5e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
            "  Building wheel for gast (setup.py): started\n",
            "  Building wheel for gast (setup.py): finished with status 'done'\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7540 sha256=9516d714a4bf523526cb6bde47e6b2275c1d3b8f8bdd0e62424a188fd3ed3ee3\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
            "  Building wheel for termcolor (setup.py): started\n",
            "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=b79a2a214f4af16c0c6f0f9e56289c316d92bb6810239abd4591620a741bff99\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
            "  Building wheel for fusepy (setup.py): started\n",
            "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
            "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=eec8f17f4d7d7401ba98fcf219730f7a3d8db2127b83c18cb803b93c9d7dfb0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
            "Successfully built wrapt gast termcolor fusepy\n",
            "Installing collected packages: wrapt, cached-property, numpy, h5py, keras-applications, six, keras-preprocessing, opt-einsum, grpcio, werkzeug, protobuf, absl-py, typing-extensions, zipp, importlib-metadata, markdown, tensorboard, gast, astor, google-pasta, termcolor, tensorflow-estimator, tensorflow, pillow, idna, chardet, urllib3, requests, isodate, oauthlib, requests-oauthlib, msrest, pycparser, cffi, cryptography, python-dateutil, PyJWT, adal, msrestazure, azure-common, azure-mgmt-keyvault, azure-mgmt-authorization, pyopenssl, backports.weakref, backports.tempfile, pathspec, pyasn1, ndg-httpsclient, websocket-client, docker, azure-mgmt-storage, azure-mgmt-resource, ruamel.yaml.clib, ruamel.yaml, jsonpickle, jmespath, jeepney, SecretStorage, contextlib2, azure-graphrbac, pytz, azure-mgmt-containerregistry, azureml-core, azureml-dataprep-native, azure-core, msal, portalocker, msal-extensions, azure-identity, cloudpickle, azureml-dataprep-rslex, distro, dotnetcore2, azureml-dataprep, pyarrow, fusepy, azureml-dataset-runtime\n",
            "Successfully installed PyJWT-2.0.1 SecretStorage-3.3.1 absl-py-0.12.0 adal-1.2.6 astor-0.8.1 azure-common-1.1.27 azure-core-1.12.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-12.1.0 azure-mgmt-storage-11.2.0 azureml-core-1.25.0 azureml-dataprep-2.11.2 azureml-dataprep-native-30.0.0 azureml-dataprep-rslex-1.9.1 azureml-dataset-runtime-1.25.0 backports.tempfile-1.0 backports.weakref-1.0.post1 cached-property-1.5.2 cffi-1.14.5 chardet-4.0.0 cloudpickle-1.6.0 contextlib2-0.6.0.post1 cryptography-3.4.7 distro-1.5.0 docker-4.4.4 dotnetcore2-2.1.20 fusepy-3.0.1 gast-0.2.2 google-pasta-0.2.0 grpcio-1.36.1 h5py-3.1.0 idna-2.10 importlib-metadata-3.9.0 isodate-0.6.0 jeepney-0.6.0 jmespath-0.10.0 jsonpickle-2.0.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.4 msal-1.10.0 msal-extensions-0.2.2 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.19.5 oauthlib-3.1.0 opt-einsum-3.3.0 pathspec-0.8.1 pillow-8.1.2 portalocker-1.7.1 protobuf-3.15.6 pyarrow-1.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-20.0.1 python-dateutil-2.8.1 pytz-2021.1 requests-2.25.1 requests-oauthlib-1.3.0 ruamel.yaml-0.17.0 ruamel.yaml.clib-0.2.2 six-1.15.0 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.4 websocket-client-0.58.0 werkzeug-1.0.1 wrapt-1.12.1 zipp-3.4.1\n",
            "\n",
            "done\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate /azureml-envs/azureml_e724c42fa12ee833d560f6a0b7166664\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "WARNING: /root/.conda/pkgs does not exist\n",
            "Removing intermediate container c19a0785667c\n",
            " ---> ccf33dce689b\n",
            "Step 9/18 : ENV PATH /azureml-envs/azureml_e724c42fa12ee833d560f6a0b7166664/bin:$PATH\n",
            " ---> Running in 17800f97465e\n",
            "Removing intermediate container 17800f97465e\n",
            " ---> 2be08e7bd8f1\n",
            "Step 10/18 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
            " ---> 6daaf8618167\n",
            "Step 11/18 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
            " ---> 0f92c9cd2ca1\n",
            "Step 12/18 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_e724c42fa12ee833d560f6a0b7166664\n",
            " ---> Running in 421d37b631a8\n",
            "Report materialized dependencies for the environment\n",
            "Reading environment context\n",
            "Exporting conda environment\n",
            "Sending request with materialized conda environment details\n",
            "Successfully sent materialized environment details\n",
            "Removing intermediate container 421d37b631a8\n",
            " ---> 70f175afbbb3\n",
            "Step 13/18 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_e724c42fa12ee833d560f6a0b7166664\n",
            " ---> Running in 94c4e58b95e1\n",
            "Removing intermediate container 94c4e58b95e1\n",
            " ---> f6d49fb2a6fc\n",
            "Step 14/18 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_e724c42fa12ee833d560f6a0b7166664/lib:$LD_LIBRARY_PATH\n",
            " ---> Running in e7fd113eb59f\n",
            "Removing intermediate container e7fd113eb59f\n",
            " ---> fa9150892910\n",
            "Step 15/18 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
            " ---> d7964af7df6c\n",
            "Step 16/18 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
            " ---> Running in 0a194113a8e7\n",
            "Removing intermediate container 0a194113a8e7\n",
            " ---> b72d654efde1\n",
            "Step 17/18 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
            " ---> Running in 9172e4c73140\n",
            "Removing intermediate container 9172e4c73140\n",
            " ---> 7866c4cd100b\n",
            "Step 18/18 : CMD [\"bash\"]\n",
            " ---> Running in 5924514f9eec\n",
            "Removing intermediate container 5924514f9eec\n",
            " ---> 441e233b2605\n",
            "Successfully built 441e233b2605\n",
            "Successfully tagged mlservice1724bc10.azurecr.io/azureml/azureml_3652ad2c593f0326e0a9ef97ceacd354:latest\n",
            "Successfully tagged mlservice1724bc10.azurecr.io/azureml/azureml_3652ad2c593f0326e0a9ef97ceacd354:1\n",
            "2021/03/29 08:32:50 Successfully executed container: acb_step_0\n",
            "2021/03/29 08:32:50 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/03/29 08:32:50 Pushing image: mlservice1724bc10.azurecr.io/azureml/azureml_3652ad2c593f0326e0a9ef97ceacd354:1, attempt 1\n",
            "The push refers to repository [mlservice1724bc10.azurecr.io/azureml/azureml_3652ad2c593f0326e0a9ef97ceacd354]\n",
            "6ef520c573d1: Preparing\n",
            "bb5a92e5cdc3: Preparing\n",
            "f7225c8fac60: Preparing\n",
            "74326b364b54: Preparing\n",
            "4fad6897b101: Preparing\n",
            "5668d4a8a40a: Preparing\n",
            "e132408a9e8c: Preparing\n",
            "fe09c46eb471: Preparing\n",
            "e0ccc567e7d3: Preparing\n",
            "3f3f8889d538: Preparing\n",
            "420340de7040: Preparing\n",
            "c3d9b0d7dd4c: Preparing\n",
            "4441896e1280: Preparing\n",
            "a64fe594a899: Preparing\n",
            "0d34930f20d5: Preparing\n",
            "18c9012f327d: Preparing\n",
            "e4a0bf630548: Preparing\n",
            "5276d2b930fc: Preparing\n",
            "e6feec0db89a: Preparing\n",
            "697949baa658: Preparing\n",
            "935c56d8b3f9: Preparing\n",
            "4441896e1280: Waiting\n",
            "a64fe594a899: Waiting\n",
            "0d34930f20d5: Waiting\n",
            "18c9012f327d: Waiting\n",
            "e4a0bf630548: Waiting\n",
            "5668d4a8a40a: Waiting\n",
            "e132408a9e8c: Waiting\n",
            "fe09c46eb471: Waiting\n",
            "e0ccc567e7d3: Waiting\n",
            "3f3f8889d538: Waiting\n",
            "420340de7040: Waiting\n",
            "c3d9b0d7dd4c: Waiting\n",
            "5276d2b930fc: Waiting\n",
            "e6feec0db89a: Waiting\n",
            "697949baa658: Waiting\n",
            "935c56d8b3f9: Waiting\n",
            "6ef520c573d1: Pushed\n",
            "74326b364b54: Pushed\n",
            "bb5a92e5cdc3: Pushed\n",
            "f7225c8fac60: Pushed\n",
            "fe09c46eb471: Pushed\n",
            "e132408a9e8c: Pushed\n",
            "e0ccc567e7d3: Pushed\n",
            "5668d4a8a40a: Pushed\n",
            "3f3f8889d538: Pushed\n",
            "420340de7040: Pushed\n",
            "c3d9b0d7dd4c: Pushed\n",
            "0d34930f20d5: Pushed\n",
            "18c9012f327d: Pushed\n",
            "5276d2b930fc: Pushed\n",
            "e6feec0db89a: Pushed\n",
            "697949baa658: Pushed\n",
            "4441896e1280: Pushed\n",
            "a64fe594a899: Pushed\n",
            "935c56d8b3f9: Pushed\n",
            "e4a0bf630548: Pushed\n",
            "4fad6897b101: Pushed\n",
            "1: digest: sha256:6834ee8010408009fff49a6c7152091e1e8175d03a2d65247cd068fcbf6fe87e size: 4721\n",
            "2021/03/29 08:34:54 Successfully pushed image: mlservice1724bc10.azurecr.io/azureml/azureml_3652ad2c593f0326e0a9ef97ceacd354:1\n",
            "2021/03/29 08:34:54 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/03/29 08:34:54 Pushing image: mlservice1724bc10.azurecr.io/azureml/azureml_3652ad2c593f0326e0a9ef97ceacd354:latest, attempt 1\n",
            "The push refers to repository [mlservice1724bc10.azurecr.io/azureml/azureml_3652ad2c593f0326e0a9ef97ceacd354]\n",
            "6ef520c573d1: Preparing\n",
            "bb5a92e5cdc3: Preparing\n",
            "f7225c8fac60: Preparing\n",
            "74326b364b54: Preparing\n",
            "4fad6897b101: Preparing\n",
            "5668d4a8a40a: Preparing\n",
            "e132408a9e8c: Preparing\n",
            "fe09c46eb471: Preparing\n",
            "e0ccc567e7d3: Preparing\n",
            "3f3f8889d538: Preparing\n",
            "420340de7040: Preparing\n",
            "c3d9b0d7dd4c: Preparing\n",
            "4441896e1280: Preparing\n",
            "a64fe594a899: Preparing\n",
            "0d34930f20d5: Preparing\n",
            "18c9012f327d: Preparing\n",
            "e4a0bf630548: Preparing\n",
            "5276d2b930fc: Preparing\n",
            "e6feec0db89a: Preparing\n",
            "697949baa658: Preparing\n",
            "935c56d8b3f9: Preparing\n",
            "5668d4a8a40a: Waiting\n",
            "c3d9b0d7dd4c: Waiting\n",
            "e132408a9e8c: Waiting\n",
            "4441896e1280: Waiting\n",
            "fe09c46eb471: Waiting\n",
            "a64fe594a899: Waiting\n",
            "e0ccc567e7d3: Waiting\n",
            "3f3f8889d538: Waiting\n",
            "0d34930f20d5: Waiting\n",
            "420340de7040: Waiting\n",
            "18c9012f327d: Waiting\n",
            "697949baa658: Waiting\n",
            "935c56d8b3f9: Waiting\n",
            "e4a0bf630548: Waiting\n",
            "5276d2b930fc: Waiting\n",
            "e6feec0db89a: Waiting\n",
            "74326b364b54: Layer already exists\n",
            "6ef520c573d1: Layer already exists\n",
            "bb5a92e5cdc3: Layer already exists\n",
            "4fad6897b101: Layer already exists\n",
            "e132408a9e8c: Layer already exists\n",
            "e0ccc567e7d3: Layer already exists\n",
            "5668d4a8a40a: Layer already exists\n",
            "fe09c46eb471: Layer already exists\n",
            "3f3f8889d538: Layer already exists\n",
            "4441896e1280: Layer already exists\n",
            "420340de7040: Layer already exists\n",
            "c3d9b0d7dd4c: Layer already exists\n",
            "a64fe594a899: Layer already exists\n",
            "0d34930f20d5: Layer already exists\n",
            "e4a0bf630548: Layer already exists\n",
            "18c9012f327d: Layer already exists\n",
            "697949baa658: Layer already exists\n",
            "e6feec0db89a: Layer already exists\n",
            "5276d2b930fc: Layer already exists\n",
            "935c56d8b3f9: Layer already exists\n",
            "f7225c8fac60: Layer already exists\n",
            "latest: digest: sha256:6834ee8010408009fff49a6c7152091e1e8175d03a2d65247cd068fcbf6fe87e size: 4721\n",
            "2021/03/29 08:34:55 Successfully pushed image: mlservice1724bc10.azurecr.io/azureml/azureml_3652ad2c593f0326e0a9ef97ceacd354:latest\n",
            "2021/03/29 08:34:55 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 179.398819)\n",
            "2021/03/29 08:34:55 Populating digests for step ID: acb_step_0...\n",
            "2021/03/29 08:34:59 Successfully populated digests for step ID: acb_step_0\n",
            "2021/03/29 08:34:59 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 123.765502)\n",
            "2021/03/29 08:34:59 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 1.597337)\n",
            "2021/03/29 08:34:59 The following dependencies were found:\n",
            "2021/03/29 08:34:59 \n",
            "- image:\n",
            "    registry: mlservice1724bc10.azurecr.io\n",
            "    repository: azureml/azureml_3652ad2c593f0326e0a9ef97ceacd354\n",
            "    tag: latest\n",
            "    digest: sha256:6834ee8010408009fff49a6c7152091e1e8175d03a2d65247cd068fcbf6fe87e\n",
            "  runtime-dependency:\n",
            "    registry: mcr.microsoft.com\n",
            "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
            "    tag: 20210301.v1\n",
            "    digest: sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            "  git: {}\n",
            "- image:\n",
            "    registry: mlservice1724bc10.azurecr.io\n",
            "    repository: azureml/azureml_3652ad2c593f0326e0a9ef97ceacd354\n",
            "    tag: \"1\"\n",
            "    digest: sha256:6834ee8010408009fff49a6c7152091e1e8175d03a2d65247cd068fcbf6fe87e\n",
            "  runtime-dependency:\n",
            "    registry: mcr.microsoft.com\n",
            "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
            "    tag: 20210301.v1\n",
            "    digest: sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            "  git: {}\n",
            "\n",
            "Run ID: cc1s was successful after 5m13s\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt\n",
            "========================================================================================================================\n",
            "2021-03-29T08:39:34Z Starting output-watcher...\n",
            "2021-03-29T08:39:34Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
            "Login Succeeded\n",
            "Using default tag: latest\n",
            "latest: Pulling from azureml/azureml_1f3c26a22a7cca7ea03b17ac7d2bb0a6\n",
            "4007a89234b4: Pulling fs layer\n",
            "5dfa26c6b9c9: Pulling fs layer\n",
            "0ba7bf18aa40: Pulling fs layer\n",
            "4c6ec688ebe3: Pulling fs layer\n",
            "a2874ccdee09: Pulling fs layer\n",
            "84e6fa394f53: Pulling fs layer\n",
            "cde35e537c55: Pulling fs layer\n",
            "08224915e098: Pulling fs layer\n",
            "3e72e2b08f2a: Pulling fs layer\n",
            "503a95eb7b7f: Pulling fs layer\n",
            "cac267f3f656: Pulling fs layer\n",
            "9c9189719fce: Pulling fs layer\n",
            "d75bfbbdd25f: Pulling fs layer\n",
            "3babcc68ce0a: Pulling fs layer\n",
            "7f5ff3a1dd4d: Pulling fs layer\n",
            "b363d6afae35: Pulling fs layer\n",
            "9e11c0c2b5c5: Pulling fs layer\n",
            "4c6ec688ebe3: Waiting\n",
            "a2874ccdee09: Waiting\n",
            "84e6fa394f53: Waiting\n",
            "503a95eb7b7f: Waiting\n",
            "3babcc68ce0a: Waiting\n",
            "cde35e537c55: Waiting\n",
            "7f5ff3a1dd4d: Waiting\n",
            "08224915e098: Waiting\n",
            "cac267f3f656: Waiting\n",
            "b363d6afae35: Waiting\n",
            "d75bfbbdd25f: Waiting\n",
            "9e11c0c2b5c5: Waiting\n",
            "9c9189719fce: Waiting\n",
            "3e72e2b08f2a: Waiting\n",
            "0ba7bf18aa40: Verifying Checksum\n",
            "0ba7bf18aa40: Download complete\n",
            "5dfa26c6b9c9: Verifying Checksum\n",
            "5dfa26c6b9c9: Download complete\n",
            "4c6ec688ebe3: Verifying Checksum\n",
            "4007a89234b4: Verifying Checksum\n",
            "4007a89234b4: Download complete\n",
            "cde35e537c55: Verifying Checksum\n",
            "cde35e537c55: Download complete\n",
            "84e6fa394f53: Verifying Checksum\n",
            "84e6fa394f53: Download complete\n",
            "a2874ccdee09: Verifying Checksum\n",
            "a2874ccdee09: Download complete\n",
            "503a95eb7b7f: Verifying Checksum\n",
            "503a95eb7b7f: Download complete\n",
            "4007a89234b4: Pull complete\n",
            "5dfa26c6b9c9: Pull complete\n",
            "0ba7bf18aa40: Pull complete\n",
            "cac267f3f656: Download complete\n",
            "4c6ec688ebe3: Pull complete\n",
            "9c9189719fce: Verifying Checksum\n",
            "9c9189719fce: Download complete\n",
            "3e72e2b08f2a: Verifying Checksum\n",
            "3e72e2b08f2a: Download complete\n",
            "08224915e098: Download complete\n",
            "7f5ff3a1dd4d: Verifying Checksum\n",
            "7f5ff3a1dd4d: Download complete\n",
            "b363d6afae35: Verifying Checksum\n",
            "b363d6afae35: Download complete\n",
            "9e11c0c2b5c5: Verifying Checksum\n",
            "9e11c0c2b5c5: Download complete\n",
            "3babcc68ce0a: Download complete\n",
            "a2874ccdee09: Pull complete\n",
            "d75bfbbdd25f: Verifying Checksum\n",
            "d75bfbbdd25f: Download complete\n",
            "84e6fa394f53: Pull complete\n",
            "cde35e537c55: Pull complete\n",
            "08224915e098: Pull complete\n",
            "3e72e2b08f2a: Pull complete\n",
            "\n",
            "Streaming azureml-logs/65_job_prep-tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d.txt\n",
            "===============================================================================================================\n",
            "[2021-03-29T08:40:03.701267] Entering job preparation.\n",
            "[2021-03-29T08:40:04.459785] Starting job preparation.\n",
            "[2021-03-29T08:40:04.459859] Extracting the control code.\n",
            "[2021-03-29T08:40:04.479460] fetching and extracting the control code on master node.\n",
            "[2021-03-29T08:40:04.479490] Starting extract_project.\n",
            "[2021-03-29T08:40:04.479550] Starting to extract zip file.\n",
            "[2021-03-29T08:40:05.184331] Finished extracting zip file.\n",
            "[2021-03-29T08:40:05.336922] Using urllib.request Python 3.0 or later\n",
            "[2021-03-29T08:40:05.336964] Start fetching snapshots.\n",
            "[2021-03-29T08:40:05.336994] Start fetching snapshot.\n",
            "[2021-03-29T08:40:05.337039] Retrieving project from snapshot: a3dee5e0-02dd-4925-ba54-3ee70ebd7b69\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 39\n",
            "[2021-03-29T08:40:05.794114] Finished fetching snapshot.\n",
            "[2021-03-29T08:40:05.794145] Start fetching snapshot.\n",
            "[2021-03-29T08:40:05.794161] Retrieving project from snapshot: d2843ced-31b7-4a5d-93c9-a81330e229e9\n",
            "[2021-03-29T08:40:17.377569] Finished fetching snapshot.\n",
            "[2021-03-29T08:40:17.377601] Finished fetching snapshots.\n",
            "[2021-03-29T08:40:17.377613] Finished extract_project.\n",
            "[2021-03-29T08:40:17.404551] Finished fetching and extracting the control code.\n",
            "[2021-03-29T08:40:17.411193] Start run_history_prep.\n",
            "[2021-03-29T08:40:17.620908] Job preparation is complete.\n",
            "[2021-03-29T08:40:17.621208] Entering Data Context Managers in Sidecar\n",
            "[2021-03-29T08:40:17.623442] Running Sidecar prep cmd...\n",
            "[2021-03-29T08:40:17.680459] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/mounts/workspaceblobstore/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e\n",
            "[2021-03-29T08:40:17.681389] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\", \"DataStoreCopy:context_managers.DataStores\"]}\n",
            "\n",
            "Streaming azureml-logs/65_job_prep-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt\n",
            "===============================================================================================================\n",
            "[2021-03-29T08:40:08.382925] Entering job preparation.\n",
            "[2021-03-29T08:40:08.977506] Starting job preparation.\n",
            "[2021-03-29T08:40:08.977542] Extracting the control code.\n",
            "[2021-03-29T08:40:08.985672] Waiting for master node to finish fetching and extracting the control code. Will check again in 1 seconds.\n",
            "[2021-03-29T08:40:09.991199] Waiting for master node to finish fetching and extracting the control code. Will check again in 3 seconds.\n",
            "[2021-03-29T08:40:12.996659] Waiting for master node to finish fetching and extracting the control code. Will check again in 5 seconds.\n",
            "[2021-03-29T08:40:18.005719] Finished fetching and extracting the control code.\n",
            "[2021-03-29T08:40:18.005909] Not a master node. Skipping rest of the context managers.\n",
            "[2021-03-29T08:40:18.005977] Entering Data Context Managers in Sidecar\n",
            "[2021-03-29T08:40:18.006605] Running Sidecar prep cmd...\n",
            "[2021-03-29T08:40:18.073814] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/mounts/workspaceblobstore/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e\n",
            "[2021-03-29T08:40:18.074683] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\", \"DataStoreCopy:context_managers.DataStores\"]}\n",
            "Enter __enter__ of DatasetContextManager\n",
            "SDK version: azureml-core==1.22.0 azureml-dataprep==2.10.1. Session id: 5faf4a88-96b0-4cb0-b930-48cb8f95ebcd. Run id: 559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e.\n",
            "Processing 'minist_param_config'.\n",
            "Processing dataset FileDataset\n",
            "{\n",
            "  \"source\": [\n",
            "    \"('mnist_datastore', 'mnist')\"\n",
            "  ],\n",
            "  \"definition\": [\n",
            "    \"GetDatastoreFiles\"\n",
            "  ],\n",
            "  \"registration\": {\n",
            "    \"id\": \"a7fc4273-f012-47f0-bc7e-9a3045deb10d\",\n",
            "    \"name\": null,\n",
            "    \"version\": null,\n",
            "    \"workspace\": \"Workspace.create(name='ml-service', subscription_id='3e0e14b3-7e28-4da7-97de-0f5cb324f030', resource_group='ml')\"\n",
            "  }\n",
            "}\n",
            "Mounting minist_param_config to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/wd/tmppavvpy3r.\n",
            "Mounted minist_param_config to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/wd/tmppavvpy3r as folder.\n",
            "Exit __enter__ of DatasetContextManager\n",
            "Set Dataset minist_param_config's target path to /mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/wd/tmppavvpy3r\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 1\n",
            "Sidecar adding paths_to_bind: ['/tmp/e425d091-6c06-4c33-88b8-712c5587076d']\n",
            "Acquired lockfile /tmp/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e-datastore.lock to downloading input data references\n",
            "[2021-03-29T08:40:27.367696] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
            "[2021-03-29T08:40:28.141195] Ran Sidecar prep cmd.\n",
            "[2021-03-29T08:40:28.141294] Running Context Managers in Sidecar complete.\n",
            "\n",
            "Streaming azureml-logs/70_driver_log.txt\n",
            "========================================\n",
            "2021/03/29 08:41:08 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
            "2021/03/29 08:41:08 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
            "[2021-03-29T08:41:09.810191] Entering context manager injector.\n",
            "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.25.0', '--scoring_module_name', 'digit_identification.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'mnist_outputs.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/mounts/workspaceblobstore/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/inferences', '--process_count_per_node', '2', '--input_fds_0', 'minist_param_config', '--input_pipeline_param_0', 'DatasetConsumptionConfig:minist_param_config'])\n",
            "Script type = None\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 107\n",
            "[2021-03-29T08:41:11.798713] Entering Run History Context Manager.\n",
            "[2021-03-29T08:41:13.358218] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/mounts/workspaceblobstore/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e\n",
            "[2021-03-29T08:41:13.358501] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.25.0', '--scoring_module_name', 'digit_identification.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'mnist_outputs.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/mounts/workspaceblobstore/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/inferences', '--process_count_per_node', '2', '--input_fds_0', 'minist_param_config', '--input_pipeline_param_0', '$minist_param_config']\n",
            "[2021-03-29T08:41:13.358591] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.25.0', '--scoring_module_name', 'digit_identification.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'mnist_outputs.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/mounts/workspaceblobstore/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/inferences', '--process_count_per_node', '2', '--input_fds_0', 'minist_param_config', '--input_pipeline_param_0', '/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/wd/tmp2j870dtd']\n",
            "\n",
            "2021/03/29 08:41:13 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt\n",
            "===============================================================================================================\n",
            "[2021-03-29T08:42:11.012723] Entering job release\n",
            "[2021-03-29T08:42:12.147209] job release stage : copy_batchai_cached_logs starting...\n",
            "[2021-03-29T08:42:12.147256] job release stage : copy_batchai_cached_logs completed...\n",
            "[2021-03-29T08:42:12.147328] Running in AzureML-Sidecar, starting to exit user context managers...\n",
            "[2021-03-29T08:42:12.156310] Running Sidecar release cmd...\n",
            "[2021-03-29T08:42:12.164937] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/mounts/workspaceblobstore/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e\n",
            "Enter __exit__ of DatasetContextManager\n",
            "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/wd/tmppavvpy3r.\n",
            "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/wd/tmppavvpy3r.\n",
            "Exit __exit__ of DatasetContextManager\n",
            "[2021-03-29T08:42:12.349476] Removing absolute paths from host...\n",
            "[2021-03-29T08:42:12.524589] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
            "[2021-03-29T08:42:13.146702] Ran Sidecar release cmd.\n",
            "\n",
            "StepRun(predict-digits-mnist) Execution Summary\n",
            "================================================\n",
            "StepRun( predict-digits-mnist ) Status: Finished\n",
            "{'runId': '559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e', 'target': 'ds3cluster', 'status': 'Completed', 'startTimeUtc': '2021-03-29T08:39:32.329322Z', 'endTimeUtc': '2021-03-29T08:42:26.508215Z', 'properties': {'ContentSnapshotId': 'a3dee5e0-02dd-4925-ba54-3ee70ebd7b69', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '7dd94648-c082-4d96-abb3-6fc2463f963f', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '09691726', 'azureml.pipelinerunid': '1d217fb3-d9cd-4be9-a772-7490b7d75795', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [{'dataset': {'id': 'a7fc4273-f012-47f0-bc7e-9a3045deb10d'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'minist_param_config', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.25.0', '--scoring_module_name', 'digit_identification.py', '--mini_batch_size', '$AML_PARAMETER_batch_size_param', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'mnist_outputs.txt', '--output', '$AZUREML_DATAREFERENCE_inferences', '--process_count_per_node', '$AML_PARAMETER_process_count_param', '--input_fds_0', 'minist_param_config', '--input_pipeline_param_0', 'DatasetConsumptionConfig:minist_param_config'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'ds3cluster', 'dataReferences': {'inferences': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/inferences', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'minist_param_config': {'dataLocation': {'dataset': {'id': 'a7fc4273-f012-47f0-bc7e-9a3045deb10d', 'name': None, 'version': None}, 'dataPath': None}, 'mechanism': 'Mount', 'environmentVariableName': 'minist_param_config', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'batch_environment', 'version': 'Autosave_2021-03-29T08:29:42Z_6d5578ba', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['tensorflow==1.15.2', 'pillow', 'azureml-core~=1.25.0', 'azureml-dataset-runtime[fuse]~=1.25.0']}], 'name': 'azureml_e724c42fa12ee833d560f6a0b7166664'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'AML_PARAMETER_batch_size_param': '5', 'AML_PARAMETER_process_count_param': '2'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=8CTTHrXtkY8tHgkYwda0StKJuKK2gK0mb7VPbK0OrG0%3D&st=2021-03-29T08%3A32%3A09Z&se=2021-03-29T16%3A42%3A09Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/azureml-logs/55_azureml-execution-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt?sv=2019-02-02&sr=b&sig=XM5WWW3342Ksh6veOKofq1pdvucPBy%2FSBvv5O9zSx6o%3D&st=2021-03-29T08%3A32%3A09Z&se=2021-03-29T16%3A42%3A09Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/azureml-logs/55_azureml-execution-tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d.txt?sv=2019-02-02&sr=b&sig=8xTooDFHgobhd4PArPUCjWVaq7PBTJhtIGuwMV7gY1A%3D&st=2021-03-29T08%3A32%3A10Z&se=2021-03-29T16%3A42%3A10Z&sp=r', 'azureml-logs/65_job_prep-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/azureml-logs/65_job_prep-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt?sv=2019-02-02&sr=b&sig=C%2BEOKslv19pKeXWRjK3AFTIak5ZBTGuifJruVnYydcU%3D&st=2021-03-29T08%3A32%3A10Z&se=2021-03-29T16%3A42%3A10Z&sp=r', 'azureml-logs/65_job_prep-tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/azureml-logs/65_job_prep-tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d.txt?sv=2019-02-02&sr=b&sig=GGGPizjkVr8o8czDLoar2F06WdAVAVBAxvGYczaBJzc%3D&st=2021-03-29T08%3A32%3A10Z&se=2021-03-29T16%3A42%3A10Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=IdJn1xqCi0q0ZQOOKQgS9RBsctfs0KBCjhEOfg%2Bn%2Fxw%3D&st=2021-03-29T08%3A32%3A10Z&se=2021-03-29T16%3A42%3A10Z&sp=r', 'azureml-logs/75_job_post-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/azureml-logs/75_job_post-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt?sv=2019-02-02&sr=b&sig=%2BnGQ2p2xv5JROAbJm6r8caJNOLuczYYjpUvSX55%2FTFc%3D&st=2021-03-29T08%3A32%3A10Z&se=2021-03-29T16%3A42%3A10Z&sp=r', 'azureml-logs/75_job_post-tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/azureml-logs/75_job_post-tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d.txt?sv=2019-02-02&sr=b&sig=cvnq%2FOjqApn1djM%2BGVbCbHvV910le%2Bf0mpIwINABUNk%3D&st=2021-03-29T08%3A32%3A10Z&se=2021-03-29T16%3A42%3A10Z&sp=r', 'azureml-logs/process_info.json': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=7QZmOPdzrwtbjAmy10PgFeSBeAeM76wchdZBUGjO0CE%3D&st=2021-03-29T08%3A32%3A10Z&se=2021-03-29T16%3A42%3A10Z&sp=r', 'azureml-logs/process_status.json': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=XVd7ki7w%2BNoi%2Bm0P4NOpZqW4qO5Q%2FANdPi6gK8iBOxM%3D&st=2021-03-29T08%3A32%3A10Z&se=2021-03-29T16%3A42%3A10Z&sp=r', 'logs/azureml/107_azureml.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/107_azureml.log?sv=2019-02-02&sr=b&sig=0zVS1jUWoR27b2xo0ux1eRF0QfJ0mW0RkNSd71me4jk%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r', 'logs/azureml/93_azureml.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/93_azureml.log?sv=2019-02-02&sr=b&sig=Kr6CvssPPgcn3OdlJlFikbASyRy%2BHONxJUR674C7q9w%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=DAQrIAdLoZsz2x76qDHg39n%2B5Ha13qJW7Vcu60q5iSA%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=J9uBvEbcO3tx2K9ePZjfguqNFtf81XrKGsgZwx3eqvU%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=GW4j4LRkPFpk3RyR%2FgC4S2CZt8T%2FBvp4JOZvMNBITkg%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=TrgL6kslRE4MhX%2B36T2ng0qEAgxL0l08Ea%2Fgj4UKJ14%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=3Kn87zoXA8YUmRoFnIhOG8OMTzPiKGLO4CAc3m24bK4%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r', 'logs/azureml/sidecar/tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d/all.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/sidecar/tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d/all.log?sv=2019-02-02&sr=b&sig=qhasPb5L2xQ0zdWOJJnPt8Dyv6t9FPScitPVHVHwAPo%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r', 'logs/azureml/sidecar/tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d/task.enter_contexts.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/sidecar/tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=Lq%2B6ZentDl%2BItjRSWO92MLiy5e0JxucY9D2HrzlDqPw%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r', 'logs/azureml/sidecar/tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d/task.exit_contexts.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/sidecar/tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=2Ord%2B5bEaP1y9I%2FtKTEDhx2joreiu0uX89FK5ngvtgc%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r', 'logs/azureml/sidecar/tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d/all.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/sidecar/tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d/all.log?sv=2019-02-02&sr=b&sig=1nkIzPhn2Q2KLxeTHQUEqPlxLvDTuRnt8CRcGe4d4W4%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r', 'logs/azureml/sidecar/tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d/task.enter_contexts.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/sidecar/tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=rg%2Fp9zAId5kYloyCUvWyc%2B4CmMEIh0Iuhj4L1RBb5Sc%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r', 'logs/azureml/sidecar/tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d/task.exit_contexts.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/sidecar/tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=ZmwHj%2BOSEL2h8%2B%2B%2FUVFcd0AwpsPUlpjESAT2D%2FYQTl0%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=tsW9s9G9uzNGfsqHuCyz4zFaa3U%2Fq%2Fqd9KBO2V6F50A%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.559bd0c1-d7d6-43f2-941b-dfe82f4e2b5e/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=g3YZQnw90s8P00ALFhDgltz2kT64FZT8riqoKdOS%2Bww%3D&st=2021-03-29T08%3A32%3A16Z&se=2021-03-29T16%3A42%3A16Z&sp=r'}, 'submittedBy': 'Anil Dwarakanath'}\n",
            "\n",
            "\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "{'runId': '1d217fb3-d9cd-4be9-a772-7490b7d75795', 'status': 'Completed', 'startTimeUtc': '2021-03-29T08:28:48.030306Z', 'endTimeUtc': '2021-03-29T08:42:30.895043Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"batch_size_param\":\"5\",\"process_count_param\":\"2\"}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.1d217fb3-d9cd-4be9-a772-7490b7d75795/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=N6SVRR0lufdIT%2BSgzzfG7OcXJHkk3saZ0rgZzxMvLlo%3D&st=2021-03-29T08%3A19%3A54Z&se=2021-03-29T16%3A29%3A54Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.1d217fb3-d9cd-4be9-a772-7490b7d75795/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=GoDCRjhUcOHIRQNXRJQx7XV29vTyFttbkU%2FX0YK8qXM%3D&st=2021-03-29T08%3A19%3A54Z&se=2021-03-29T16%3A29%3A54Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.1d217fb3-d9cd-4be9-a772-7490b7d75795/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=w9A4m1MWuOLG1AE5AreJHftBPY7N1WDdRTFzsBnadxo%3D&st=2021-03-29T08%3A19%3A54Z&se=2021-03-29T16%3A29%3A54Z&sp=r'}, 'submittedBy': 'Anil Dwarakanath'}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Finished'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Wait the run for completion and show output log to console\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View the prediction results per input image\n",
        "In the digit_identification.py file above you can see that the ResultList with the filename and the prediction result gets returned. These are written to the DataStore specified in the PipelineData object as the output data, which in this case is called *inferences*. This containers the outputs from  all of the worker nodes used in the compute cluster. You can download this data to view the results ... below just filters to the first 10 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction has  1000  rows\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Filename  Prediction\n",
              "0    0.png           7\n",
              "1    1.png           2\n",
              "2   10.png           0\n",
              "3  100.png           6\n",
              "4  101.png           0\n",
              "5  161.png           6\n",
              "6  162.png           5\n",
              "7  163.png           4\n",
              "8  164.png           6\n",
              "9  165.png           5"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filename</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.png</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.png</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100.png</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>101.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>161.png</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>162.png</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>163.png</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>164.png</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>165.png</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tempfile\n",
        "\n",
        "batch_run = pipeline_run.find_step_run(parallelrun_step.name)[0]\n",
        "batch_output = batch_run.get_output_data(output_dir.name)\n",
        "\n",
        "target_dir = tempfile.mkdtemp()\n",
        "batch_output.download(local_path=target_dir)\n",
        "result_file = os.path.join(target_dir, batch_output.path_on_datastore, parallel_run_config.append_row_file_name)\n",
        "\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
        "df.columns = [\"Filename\", \"Prediction\"]\n",
        "print(\"Prediction has \", df.shape[0], \" rows\")\n",
        "df.head(10) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Resubmit a with different dataset\n",
        "Since we made the input a `PipelineParameter`, we can resubmit with a different dataset without having to create an entirely new experiment. We'll use the same datastore but use only a single image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_on_datastore = mnist_data.path('mnist/0.png')\n",
        "single_image_ds = Dataset.File.from_files(path=path_on_datastore, validate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitted PipelineRun 87f4f4e1-4eea-4226-8ed3-4c50ac22d293\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/87f4f4e1-4eea-4226-8ed3-4c50ac22d293?wsid=/subscriptions/3e0e14b3-7e28-4da7-97de-0f5cb324f030/resourcegroups/ml/workspaces/ml-service&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
          ]
        }
      ],
      "source": [
        "pipeline_run_2 = experiment.submit(pipeline, \n",
        "                                   pipeline_parameters={\"mnist_param\": single_image_ds, \n",
        "                                                        \"batch_size_param\": \"1\",\n",
        "                                                        \"process_count_param\": 1}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Run(Experiment: digit_identification,\n",
              "Id: 87f4f4e1-4eea-4226-8ed3-4c50ac22d293,\n",
              "Type: azureml.PipelineRun,\n",
              "Status: Preparing)"
            ],
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>digit_identification</td><td>87f4f4e1-4eea-4226-8ed3-4c50ac22d293</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/87f4f4e1-4eea-4226-8ed3-4c50ac22d293?wsid=/subscriptions/3e0e14b3-7e28-4da7-97de-0f5cb324f030/resourcegroups/ml/workspaces/ml-service&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# This will output information of the pipeline run, including the link to the details page of portal.\n",
        "pipeline_run_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineRunId: 87f4f4e1-4eea-4226-8ed3-4c50ac22d293\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/87f4f4e1-4eea-4226-8ed3-4c50ac22d293?wsid=/subscriptions/3e0e14b3-7e28-4da7-97de-0f5cb324f030/resourcegroups/ml/workspaces/ml-service&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: 67fcd9f8-4f04-4e0b-841f-712296f8689b\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/67fcd9f8-4f04-4e0b-841f-712296f8689b?wsid=/subscriptions/3e0e14b3-7e28-4da7-97de-0f5cb324f030/resourcegroups/ml/workspaces/ml-service&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "StepRun( predict-digits-mnist ) Status: Running\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt\n",
            "========================================================================================================================\n",
            "2021-03-29T08:50:56Z Starting output-watcher...\n",
            "2021-03-29T08:50:56Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
            "Login Succeeded\n",
            "Using default tag: latest\n",
            "latest: Pulling from azureml/azureml_1f3c26a22a7cca7ea03b17ac7d2bb0a6\n",
            "Digest: sha256:9c1b3720e6155847eb0701e3285ffd89726766aea739759fc97e5d3b59db3313\n",
            "Status: Image is up to date for viennaglobal.azurecr.io/azureml/azureml_1f3c26a22a7cca7ea03b17ac7d2bb0a6:latest\n",
            "viennaglobal.azurecr.io/azureml/azureml_1f3c26a22a7cca7ea03b17ac7d2bb0a6:latest\n",
            "2021-03-29T08:50:58Z Check if container 67fcd9f8-4f04-4e0b-841f-712296f8689b already exist exited with 0, \n",
            "\n",
            "5115da60dfaf7a23cdda164cdf3f336074021506d93ebe2b70af158193cbbcb3\n",
            "2021-03-29T08:50:59Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
            "2021-03-29T08:50:59Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-6038da17ebf2a6765f83cd42ffe242b1-c5127e0d4477318b-01 -sshRequired=false] \n",
            "2021/03/29 08:50:59 Starting App Insight Logger for task:  containerSetup\n",
            "2021/03/29 08:50:59 Version: 3.0.01535.0005 Branch: 34 Commit: cd98749\n",
            "2021/03/29 08:50:59 Entered ContainerSetupTask - Preparing infiniband\n",
            "2021/03/29 08:50:59 Starting infiniband setup\n",
            "2021/03/29 08:50:59 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
            "2021/03/29 08:50:59 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
            "2021/03/29 08:50:59 sshd inside container not required for job, skipping setup.\n",
            "2021/03/29 08:51:00 All App Insights Logs was send successfully\n",
            "2021/03/29 08:51:00 App Insight Client has already been closed\n",
            "2021/03/29 08:51:00 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "2021-03-29T08:51:00Z Starting docker container succeeded.\n",
            "\n",
            "Streaming azureml-logs/65_job_prep-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt\n",
            "===============================================================================================================\n",
            "[2021-03-29T08:51:01.135481] Entering job preparation.\n",
            "[2021-03-29T08:51:01.737798] Starting job preparation.\n",
            "[2021-03-29T08:51:01.737847] Extracting the control code.\n",
            "[2021-03-29T08:51:01.746510] Waiting for master node to finish fetching and extracting the control code. Will check again in 1 seconds.\n",
            "[2021-03-29T08:51:02.751021] Waiting for master node to finish fetching and extracting the control code. Will check again in 3 seconds.\n",
            "[2021-03-29T08:51:05.757836] Waiting for master node to finish fetching and extracting the control code. Will check again in 5 seconds.\n",
            "[2021-03-29T08:51:10.768042] Waiting for master node to finish fetching and extracting the control code. Will check again in 7 seconds.\n",
            "[2021-03-29T08:51:17.772785] Finished fetching and extracting the control code.\n",
            "[2021-03-29T08:51:17.772987] Not a master node. Skipping rest of the context managers.\n",
            "[2021-03-29T08:51:17.773050] Entering Data Context Managers in Sidecar\n",
            "[2021-03-29T08:51:17.773665] Running Sidecar prep cmd...\n",
            "[2021-03-29T08:51:17.829205] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/mounts/workspaceblobstore/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b\n",
            "[2021-03-29T08:51:17.830265] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\", \"DataStoreCopy:context_managers.DataStores\"]}\n",
            "Enter __enter__ of DatasetContextManager\n",
            "SDK version: azureml-core==1.22.0 azureml-dataprep==2.10.1. Session id: d820a606-891f-4c48-a127-5ac58ae3a9d6. Run id: 67fcd9f8-4f04-4e0b-841f-712296f8689b.\n",
            "Processing 'minist_param_config'.\n",
            "Processing dataset FileDataset\n",
            "{\n",
            "  \"source\": [\n",
            "    \"('mnist_datastore', 'mnist/0.png')\"\n",
            "  ],\n",
            "  \"definition\": [\n",
            "    \"GetDatastoreFiles\"\n",
            "  ],\n",
            "  \"registration\": {\n",
            "    \"id\": \"b02da1ba-a016-4eab-8bab-98459140d9db\",\n",
            "    \"name\": null,\n",
            "    \"version\": null,\n",
            "    \"workspace\": \"Workspace.create(name='ml-service', subscription_id='3e0e14b3-7e28-4da7-97de-0f5cb324f030', resource_group='ml')\"\n",
            "  }\n",
            "}\n",
            "Mounting minist_param_config to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/wd/tmpcl8po13v.\n",
            "Mounted minist_param_config to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/wd/tmpcl8po13v as single file.\n",
            "Exit __enter__ of DatasetContextManager\n",
            "Set Dataset minist_param_config's target path to /mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/wd/tmpcl8po13v/0.png\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 1\n",
            "Sidecar adding paths_to_bind: ['/tmp/5704c7ce-d80f-4bd8-add6-64ca10aa0c1e']\n",
            "Acquired lockfile /tmp/67fcd9f8-4f04-4e0b-841f-712296f8689b-datastore.lock to downloading input data references\n",
            "[2021-03-29T08:51:26.918314] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
            "[2021-03-29T08:51:28.088254] Ran Sidecar prep cmd.\n",
            "[2021-03-29T08:51:28.088390] Running Context Managers in Sidecar complete.\n",
            "\n",
            "Streaming azureml-logs/70_driver_log.txt\n",
            "========================================\n",
            "2021/03/29 08:51:32 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
            "2021/03/29 08:51:32 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
            "[2021-03-29T08:51:34.148886] Entering context manager injector.\n",
            "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.25.0', '--scoring_module_name', 'digit_identification.py', '--mini_batch_size', '1', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'mnist_outputs.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/mounts/workspaceblobstore/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/inferences', '--process_count_per_node', '1', '--input_fds_0', 'minist_param_config', '--input_pipeline_param_0', 'DatasetConsumptionConfig:minist_param_config'])\n",
            "Script type = None\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 109\n",
            "[2021-03-29T08:51:36.226555] Entering Run History Context Manager.\n",
            "[2021-03-29T08:51:37.324722] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/mounts/workspaceblobstore/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b\n",
            "[2021-03-29T08:51:37.324914] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.25.0', '--scoring_module_name', 'digit_identification.py', '--mini_batch_size', '1', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'mnist_outputs.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/mounts/workspaceblobstore/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/inferences', '--process_count_per_node', '1', '--input_fds_0', 'minist_param_config', '--input_pipeline_param_0', '$minist_param_config']\n",
            "[2021-03-29T08:51:37.324977] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.25.0', '--scoring_module_name', 'digit_identification.py', '--mini_batch_size', '1', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'mnist_outputs.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/mounts/workspaceblobstore/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/inferences', '--process_count_per_node', '1', '--input_fds_0', 'minist_param_config', '--input_pipeline_param_0', '/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/wd/tmp61zejx0w/0.png']\n",
            "\n",
            "2021/03/29 08:51:37 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt\n",
            "===============================================================================================================\n",
            "[2021-03-29T08:52:26.197655] Entering job release\n",
            "[2021-03-29T08:52:27.217954] job release stage : copy_batchai_cached_logs starting...\n",
            "[2021-03-29T08:52:27.218016] job release stage : copy_batchai_cached_logs completed...\n",
            "[2021-03-29T08:52:27.218084] Running in AzureML-Sidecar, starting to exit user context managers...\n",
            "[2021-03-29T08:52:27.228979] Running Sidecar release cmd...\n",
            "[2021-03-29T08:52:27.236842] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/mounts/workspaceblobstore/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b\n",
            "Enter __exit__ of DatasetContextManager\n",
            "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/wd/tmpcl8po13v.\n",
            "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-service/azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/wd/tmpcl8po13v.\n",
            "Exit __exit__ of DatasetContextManager\n",
            "[2021-03-29T08:52:27.445364] Removing absolute paths from host...\n",
            "[2021-03-29T08:52:27.787269] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
            "[2021-03-29T08:52:28.429347] Ran Sidecar release cmd.\n",
            "\n",
            "StepRun(predict-digits-mnist) Execution Summary\n",
            "================================================\n",
            "StepRun( predict-digits-mnist ) Status: Finished\n",
            "{'runId': '67fcd9f8-4f04-4e0b-841f-712296f8689b', 'target': 'ds3cluster', 'status': 'Completed', 'startTimeUtc': '2021-03-29T08:50:52.425953Z', 'endTimeUtc': '2021-03-29T08:52:38.131215Z', 'properties': {'ContentSnapshotId': 'a3dee5e0-02dd-4925-ba54-3ee70ebd7b69', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '7dd94648-c082-4d96-abb3-6fc2463f963f', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '09691726', 'azureml.pipelinerunid': '87f4f4e1-4eea-4226-8ed3-4c50ac22d293', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [{'dataset': {'id': 'b02da1ba-a016-4eab-8bab-98459140d9db'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'minist_param_config', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.25.0', '--scoring_module_name', 'digit_identification.py', '--mini_batch_size', '$AML_PARAMETER_batch_size_param', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'mnist_outputs.txt', '--output', '$AZUREML_DATAREFERENCE_inferences', '--process_count_per_node', '$AML_PARAMETER_process_count_param', '--input_fds_0', 'minist_param_config', '--input_pipeline_param_0', 'DatasetConsumptionConfig:minist_param_config'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'ds3cluster', 'dataReferences': {'inferences': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/67fcd9f8-4f04-4e0b-841f-712296f8689b/inferences', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'minist_param_config': {'dataLocation': {'dataset': {'id': 'b02da1ba-a016-4eab-8bab-98459140d9db', 'name': None, 'version': None}, 'dataPath': None}, 'mechanism': 'Mount', 'environmentVariableName': 'minist_param_config', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'batch_environment', 'version': 'Autosave_2021-03-29T08:50:43Z_ea2ecd4c', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['tensorflow==1.15.2', 'pillow', 'azureml-core~=1.25.0', 'azureml-dataset-runtime[fuse]~=1.25.0']}], 'name': 'azureml_e724c42fa12ee833d560f6a0b7166664'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'AML_PARAMETER_batch_size_param': '1', 'AML_PARAMETER_process_count_param': '1'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/azureml-logs/55_azureml-execution-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt?sv=2019-02-02&sr=b&sig=O255nquDew7zIWqGAj%2FMWmR3jCDTGrNIBTfprQaj1MM%3D&st=2021-03-29T08%3A42%3A29Z&se=2021-03-29T16%3A52%3A29Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/azureml-logs/55_azureml-execution-tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d.txt?sv=2019-02-02&sr=b&sig=MdUrL1AYQ9vt1QgqoqRjbUsAyEJXEaRhLQZZ1MDqdz4%3D&st=2021-03-29T08%3A42%3A29Z&se=2021-03-29T16%3A52%3A29Z&sp=r', 'azureml-logs/65_job_prep-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/azureml-logs/65_job_prep-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt?sv=2019-02-02&sr=b&sig=ZIuuzeJK73UcUC1Bm%2F8yWxqJkQrWRRL1mdmJX9r9gE4%3D&st=2021-03-29T08%3A42%3A29Z&se=2021-03-29T16%3A52%3A29Z&sp=r', 'azureml-logs/65_job_prep-tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/azureml-logs/65_job_prep-tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d.txt?sv=2019-02-02&sr=b&sig=t4fSofodUlITh2LxU3NOkxn7pN0HYn%2FewlxVag91zFU%3D&st=2021-03-29T08%3A42%3A29Z&se=2021-03-29T16%3A52%3A29Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=EBelCWwJrg8xblJhiKpOhwvH0OIy6vLTMVY7bivHfSU%3D&st=2021-03-29T08%3A42%3A29Z&se=2021-03-29T16%3A52%3A29Z&sp=r', 'azureml-logs/75_job_post-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/azureml-logs/75_job_post-tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d.txt?sv=2019-02-02&sr=b&sig=25JG5GDFKJyz%2FFFj3IjexufX7DfxdaUId%2BkDoV4RnbQ%3D&st=2021-03-29T08%3A42%3A29Z&se=2021-03-29T16%3A52%3A29Z&sp=r', 'azureml-logs/75_job_post-tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/azureml-logs/75_job_post-tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d.txt?sv=2019-02-02&sr=b&sig=iTJ78wVeXTNd6cWyM0zKhBHTMV6xXC%2Fz3Bvbzwq1UNM%3D&st=2021-03-29T08%3A42%3A29Z&se=2021-03-29T16%3A52%3A29Z&sp=r', 'azureml-logs/process_info.json': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=1ufn%2FsbrRHT20vr6qCNl6q3Q6QbBhjLfP9EQd%2FJOCHQ%3D&st=2021-03-29T08%3A42%3A29Z&se=2021-03-29T16%3A52%3A29Z&sp=r', 'azureml-logs/process_status.json': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=izIwFzp5v2JLdpnz8ZT7xI03v6VImvhMmoB0OVsmj2g%3D&st=2021-03-29T08%3A42%3A29Z&se=2021-03-29T16%3A52%3A29Z&sp=r', 'logs/azureml/109_azureml.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/109_azureml.log?sv=2019-02-02&sr=b&sig=YH7K69w9RLiXwUWTiBLRqrQrFSgt8hUc3YgOmcqFONA%3D&st=2021-03-29T08%3A42%3A24Z&se=2021-03-29T16%3A52%3A24Z&sp=r', 'logs/azureml/93_azureml.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/93_azureml.log?sv=2019-02-02&sr=b&sig=Mq2ywAZf4L%2BX642kI5FdHL4n9oGq52vn3QncrzTtpkg%3D&st=2021-03-29T08%3A42%3A24Z&se=2021-03-29T16%3A52%3A24Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=oZ0wJt1jVZVcgwC43QZFxBG1lZx56qYkJrDrxmyonRU%3D&st=2021-03-29T08%3A42%3A24Z&se=2021-03-29T16%3A52%3A24Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=Mlp7%2BHhCB5gg8ghElmx%2FiVRHEIYr4rzqUIrpyNWhJq8%3D&st=2021-03-29T08%3A42%3A24Z&se=2021-03-29T16%3A52%3A24Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=7nbkIwoxvkzFAW5In2ly%2BRdfGw2jKOg4Pb7wpRX0Ndc%3D&st=2021-03-29T08%3A42%3A24Z&se=2021-03-29T16%3A52%3A24Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=SoSdGB5iHmbbNDVCyrUDamY5L0GYFfsMQdrQF7fPQTQ%3D&st=2021-03-29T08%3A42%3A24Z&se=2021-03-29T16%3A52%3A24Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=MeNYa2NyqA2hW3KdoKE%2FE9MkhsD52tuy9fb7NA%2FHmek%3D&st=2021-03-29T08%3A42%3A24Z&se=2021-03-29T16%3A52%3A24Z&sp=r', 'logs/azureml/sidecar/tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d/all.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/sidecar/tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d/all.log?sv=2019-02-02&sr=b&sig=wovMOniXm853WRA1pib4vzDfzdSxxeb1IIH4HAZpagU%3D&st=2021-03-29T08%3A42%3A24Z&se=2021-03-29T16%3A52%3A24Z&sp=r', 'logs/azureml/sidecar/tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d/task.enter_contexts.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/sidecar/tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=yHwQ1dGu6jrje0HowvFOBYA9kDeSWeDt9TIW03wXPvw%3D&st=2021-03-29T08%3A42%3A24Z&se=2021-03-29T16%3A52%3A24Z&sp=r', 'logs/azureml/sidecar/tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d/task.exit_contexts.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/sidecar/tvmps_11d6e793169222820dcef1afc63ff3c352409a69c79a9d308e9a7de38cffca56_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=Cr6zqn7MeKrWSwBoaAmLr7u5tx5b5323fCFh3U9XiZQ%3D&st=2021-03-29T08%3A42%3A24Z&se=2021-03-29T16%3A52%3A24Z&sp=r', 'logs/azureml/sidecar/tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d/all.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/sidecar/tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d/all.log?sv=2019-02-02&sr=b&sig=1dIUd38PIo5mlf5TSkhXkCf8rA1drBm9LEISx7AKGiw%3D&st=2021-03-29T08%3A42%3A25Z&se=2021-03-29T16%3A52%3A25Z&sp=r', 'logs/azureml/sidecar/tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d/task.enter_contexts.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/sidecar/tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=HUMylEVtkXxODUwK83VTv7ZE75M3AIQthefKqVhdgvg%3D&st=2021-03-29T08%3A42%3A25Z&se=2021-03-29T16%3A52%3A25Z&sp=r', 'logs/azureml/sidecar/tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d/task.exit_contexts.log': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/sidecar/tvmps_c9ceb16b4a6ffbe4c6c957c395a9b6dcbf006b84c4cdcb0dc4c7e1dbb39418c8_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=APMUo2jZfhHeWynR9iJOzmZfDvHJRTp4JJaYXO9dGec%3D&st=2021-03-29T08%3A42%3A25Z&se=2021-03-29T16%3A52%3A25Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=xwgq9jKJRgvexTL512nlJgyphn5QTJkP7l8jiixaNis%3D&st=2021-03-29T08%3A42%3A25Z&se=2021-03-29T16%3A52%3A25Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.67fcd9f8-4f04-4e0b-841f-712296f8689b/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=WhHe2gdCNkQzPlmtw%2Fy5a9CdkaWh4k%2FR17lkOZg1kb4%3D&st=2021-03-29T08%3A42%3A25Z&se=2021-03-29T16%3A52%3A25Z&sp=r'}, 'submittedBy': 'Anil Dwarakanath'}\n",
            "\n",
            "\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "{'runId': '87f4f4e1-4eea-4226-8ed3-4c50ac22d293', 'status': 'Completed', 'startTimeUtc': '2021-03-29T08:50:38.978512Z', 'endTimeUtc': '2021-03-29T08:52:40.201083Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"batch_size_param\":\"1\",\"process_count_param\":\"1\"}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.87f4f4e1-4eea-4226-8ed3-4c50ac22d293/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=c2hgE9qfhUs547KvwJ0m%2FQusZBVUUkUM0%2FUdr2beTYM%3D&st=2021-03-29T08%3A42%3A42Z&se=2021-03-29T16%3A52%3A42Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.87f4f4e1-4eea-4226-8ed3-4c50ac22d293/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=TBqm3m4LttFB8sVoIaHfqUXDzoY7oofBc7gCf2dUugM%3D&st=2021-03-29T08%3A42%3A42Z&se=2021-03-29T16%3A52%3A42Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlservice7009088601.blob.core.windows.net/azureml/ExperimentRun/dcid.87f4f4e1-4eea-4226-8ed3-4c50ac22d293/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=7UTMhdt2aGy7MvyzNrPbkqQ29%2FH1q2ZX6K2jrGKm%2FkM%3D&st=2021-03-29T08%3A42%3A42Z&se=2021-03-29T16%3A52%3A42Z&sp=r'}, 'submittedBy': 'Anil Dwarakanath'}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Finished'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Wait the run for completion and show output log to console\n",
        "pipeline_run_2.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup Compute resources\n",
        "\n",
        "For re-occurring jobs, it may be wise to keep compute the compute resources and allow compute nodes to scale down to 0. However, since this is just a single-run job, we are free to release the allocated compute resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# uncomment below and run if compute resources are no longer needed \n",
        "# compute_target.delete() "
      ]
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "joringer"
      },
      {
        "name": "asraniwa"
      },
      {
        "name": "pansav"
      },
      {
        "name": "tracych"
      }
    ],
    "category": "Other notebooks",
    "compute": [
      "AML Compute"
    ],
    "datasets": [
      "MNIST"
    ],
    "deployment": [
      "None"
    ],
    "exclude_from_index": false,
    "framework": [
      "None"
    ],
    "friendly_name": "MNIST data inferencing using ParallelRunStep",
    "index_order": 1,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.10 64-bit ('aml': conda)",
      "metadata": {
        "interpreter": {
          "hash": "a5d4df4a22655ddcd3995113ae21abdf5e3f153b58eb8770b042525e3ea05670"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10-final"
    },
    "tags": [
      "Batch Inferencing",
      "Pipeline"
    ],
    "task": "Digit identification"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}